{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "* [Overview](#Overview)\n",
    "* [Setup](#Setup)\n",
    "* [Lasso](#Lasso)\n",
    "\n",
    "# Overview\n",
    "\n",
    "This script covers how to implement two techniques:\n",
    "1. Regularization\n",
    "2. Cross-validation\n",
    "\n",
    "Regularization is a shrinkage estimator. \n",
    "By adding an additional constraint on the optimization problem, the coefficients will be smaller than their non-constrained counterparts.\n",
    "With an absolute constraint, it can be used to **select** features by setting coefficients to zero.\n",
    "The shrinkage strength is determined by a hyperpameter $\\lambda$, where $\\lambda = 0$ is no shrinkage.\n",
    "\n",
    "Cross-validation is a ubiquitous machine learning technique used **tune** hyperparameters.\n",
    "Where train-test splits are used to compare across model classes, cross-validation is used for comparing within model classes.\n",
    "See the lecture slides for more details.\n",
    "\n",
    "***\n",
    "# Setup\n",
    "[TOP](#Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pct_d_rgdp', 'urate_bin', 'pos_net_jobs', 'emp_estabs',\n",
       "       'estabs_entry_rate', 'estabs_exit_rate', 'pop', 'pop_pct_black',\n",
       "       'pop_pct_hisp', 'lfpr', 'density', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['urate_bin', 'year']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df.year, drop_first = True)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['pct_d_rgdp']\n",
    "x = df_prepped.drop(columns = 'pct_d_rgdp')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)\n",
    "\n",
    "###################################################\n",
    "# Be careful if you have a large data set.        #\n",
    "# We have created ~4 copies of the original data: #\n",
    "#                                                 #\n",
    "# 0. df                                           #\n",
    "# 1. df_prepped                                   #\n",
    "# 2. x, y                                         #\n",
    "# 3. x_train, x_test, y_train, y_test             #\n",
    "# 4. x_train_std, x_test_std                      #\n",
    "#                                                 #\n",
    "# you may run out of memeory                      #\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Lasso\n",
    "[TOP](#Regularization)\n",
    "\n",
    "`statsmodels` fits an elastic-net constraint, which is a hybrid of Lasso and Ridge regression. \n",
    "It has the penalty:\n",
    "$$\n",
    "\\alpha \\left[ (1-L1\\_wt)||\\beta||_2 + L1\\_wt||\\beta||_1 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18029875,  0.07878553, -0.02016176,  0.09040581, -0.0217023 ,\n",
       "       -0.0008972 , -0.0352795 ,  0.030556  ,  0.06993904, -0.00115653,\n",
       "        0.05257679, -0.00836787,  0.02187259,  0.01610148,  0.01629544,\n",
       "        0.05894326, -0.01071656, -0.02457684, -0.05852966,  0.01871018,\n",
       "        0.00076798, -0.02270842,  0.0151311 , -0.0134313 , -0.00444493,\n",
       "       -0.0382363 , -0.00899301,  0.00820053])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ridge = sm.OLS(y_train, x_train_std).fit_regularized(alpha = 10, L1_wt = 0)\n",
    "# note: there is no fit.summary()\n",
    "fit_ridge.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                0.0\n",
       "pos_net_jobs         0.0\n",
       "emp_estabs           0.0\n",
       "estabs_entry_rate    0.0\n",
       "estabs_exit_rate     0.0\n",
       "pop                  0.0\n",
       "pop_pct_black        0.0\n",
       "pop_pct_hisp         0.0\n",
       "lfpr                 0.0\n",
       "density              0.0\n",
       "lower                0.0\n",
       "similar              0.0\n",
       "2003                 0.0\n",
       "2004                 0.0\n",
       "2005                 0.0\n",
       "2006                 0.0\n",
       "2007                 0.0\n",
       "2008                 0.0\n",
       "2009                 0.0\n",
       "2010                 0.0\n",
       "2011                 0.0\n",
       "2012                 0.0\n",
       "2013                 0.0\n",
       "2014                 0.0\n",
       "2015                 0.0\n",
       "2016                 0.0\n",
       "2017                 0.0\n",
       "2018                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso = sm.OLS(y_train, x_train_std).fit_regularized(alpha = 10, L1_wt = 1)\n",
    "# note: there is no fit.summary()\n",
    "fit_lasso.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Cross-Validation \n",
    "[TOP](#Regularization)\n",
    "\n",
    "We are using a specific type of k-fold cross-validation: grid search.\n",
    "When performing grid search cross-validation, you always want to ensure that your selected hyperparameters are an interior point of the grid. \n",
    "Otherwise, you have no selected the optimal solution.\n",
    "\n",
    "The grid search function is from `sklearn`.\n",
    "Consequently, we need to use functions from the `linear_model` module: https://scikit-learn.org/stable/modules/linear_model.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lasso = sm.OLS(y_train, x_train_std).fit_regularized(alpha = 10, L1_wt = 1)\n",
    "# note: there is no fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'alpha': 10**np.linspace(-2, 2, num = 20)}\n",
    "]\n",
    "\n",
    "# We are manually supplying an intercept\n",
    "# and standardized (not normalized) the features\n",
    "cv_lasso = lm.Lasso(fit_intercept = False, normalize = False,\n",
    "                    random_state = 490)\n",
    "grid_search = GridSearchCV(cv_lasso, param_grid, cv = 5,\n",
    "                         scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best = grid_search.best_params_['alpha']\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interior point ($10^{-2} = 0.01$). \n",
    "We need to adjust our grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003359818286283781"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'alpha': 10**np.linspace(-5, -2, num = 20)}\n",
    "]\n",
    "\n",
    "cv_lasso = lm.Lasso(fit_intercept = False, normalize = False,\n",
    "                    random_state = 490)\n",
    "\n",
    "grid_search = GridSearchCV(cv_lasso, param_grid, cv = 5,\n",
    "                         scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_['alpha']\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Once we have identified the best value of $\\alpha$, then the next step is to estimate the full model. \n",
    "We will use `statsmodels` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                1.979926\n",
       "pos_net_jobs         0.555051\n",
       "emp_estabs          -0.175141\n",
       "estabs_entry_rate    0.896385\n",
       "estabs_exit_rate    -0.519264\n",
       "pop                 -0.102140\n",
       "pop_pct_black        0.014655\n",
       "pop_pct_hisp         0.304292\n",
       "lfpr                 0.489863\n",
       "density             -0.005985\n",
       "lower                0.601362\n",
       "similar              0.250107\n",
       "2003                 0.000000\n",
       "2004                -0.069857\n",
       "2005                 0.063817\n",
       "2006                 0.436949\n",
       "2007                -0.323667\n",
       "2008                -0.354894\n",
       "2009                -0.545083\n",
       "2010                 0.168481\n",
       "2011                -0.088483\n",
       "2012                -0.383047\n",
       "2013                 0.028383\n",
       "2014                -0.309390\n",
       "2015                -0.230910\n",
       "2016                -0.581017\n",
       "2017                -0.211965\n",
       "2018                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso_tuned = sm.OLS(y_train, x_train_std).fit_regularized(L1_wt = 1, alpha = best)\n",
    "fit_lasso_tuned.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Remember, a regularized model is biased.\n",
    "We will fit \n",
    "\n",
    "- a non-regularized standardized model excluding the features that are zero \n",
    "- a non-regularized, non-standardized model excluding the features that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([2003, 2018], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = fit_lasso_tuned.params\n",
    "beta.index[beta == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std_trim = x_train_std.loc[:, ~x_train_std.columns.isin(beta.index[beta == 0])]\n",
    "x_test_std_trim = x_test_std.loc[:, ~x_test_std.columns.isin(beta.index[beta == 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>      <td>0.041</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>pct_d_rgdp</td>           <td>AIC:</td>         <td>246977.3317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-02-25 14:24</td>        <td>BIC:</td>         <td>247196.5337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33889</td>        <td>Log-Likelihood:</td>   <td>-1.2346e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>25</td>           <td>F-statistic:</td>        <td>58.31</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33863</td>      <td>Prob (F-statistic):</td>  <td>4.48e-286</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.041</td>            <td>Scale:</td>          <td>85.557</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>1.9833</td>   <td>0.0502</td>   <td>39.4717</td> <td>0.0000</td> <td>1.8848</td>  <td>2.0818</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>0.5576</td>   <td>0.0542</td>   <td>10.2891</td> <td>0.0000</td> <td>0.4514</td>  <td>0.6638</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>-0.1799</td>  <td>0.0543</td>   <td>-3.3099</td> <td>0.0009</td> <td>-0.2864</td> <td>-0.0733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.8986</td>   <td>0.0597</td>   <td>15.0624</td> <td>0.0000</td> <td>0.7817</td>  <td>1.0155</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.5245</td>  <td>0.0579</td>   <td>-9.0616</td> <td>0.0000</td> <td>-0.6380</td> <td>-0.4111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-0.1051</td>  <td>0.0567</td>   <td>-1.8529</td> <td>0.0639</td> <td>-0.2164</td> <td>0.0061</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>0.0231</td>   <td>0.0573</td>   <td>0.4031</td>  <td>0.6869</td> <td>-0.0893</td> <td>0.1355</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.3096</td>   <td>0.0522</td>   <td>5.9342</td>  <td>0.0000</td> <td>0.2073</td>  <td>0.4118</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.4921</td>   <td>0.0624</td>   <td>7.8888</td>  <td>0.0000</td> <td>0.3698</td>  <td>0.6144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>-0.0089</td>  <td>0.0540</td>   <td>-0.1646</td> <td>0.8693</td> <td>-0.1147</td> <td>0.0969</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>0.6103</td>   <td>0.0684</td>   <td>8.9266</td>  <td>0.0000</td> <td>0.4763</td>  <td>0.7443</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.2587</td>   <td>0.0590</td>   <td>4.3821</td>  <td>0.0000</td> <td>0.1430</td>  <td>0.3745</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>-0.0797</td>  <td>0.0565</td>   <td>-1.4104</td> <td>0.1584</td> <td>-0.1904</td> <td>0.0310</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>0.0635</td>   <td>0.0603</td>   <td>1.0525</td>  <td>0.2926</td> <td>-0.0547</td> <td>0.1816</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>0.4367</td>   <td>0.0613</td>   <td>7.1289</td>  <td>0.0000</td> <td>0.3166</td>  <td>0.5568</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>-0.3333</td>  <td>0.0566</td>   <td>-5.8880</td> <td>0.0000</td> <td>-0.4442</td> <td>-0.2223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>-0.3639</td>  <td>0.0566</td>   <td>-6.4307</td> <td>0.0000</td> <td>-0.4748</td> <td>-0.2530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-0.5530</td>  <td>0.0580</td>   <td>-9.5330</td> <td>0.0000</td> <td>-0.6668</td> <td>-0.4393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>0.1662</td>   <td>0.0571</td>   <td>2.9088</td>  <td>0.0036</td> <td>0.0542</td>  <td>0.2782</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>-0.0976</td>  <td>0.0569</td>   <td>-1.7135</td> <td>0.0866</td> <td>-0.2092</td> <td>0.0140</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>-0.3924</td>  <td>0.0569</td>   <td>-6.8997</td> <td>0.0000</td> <td>-0.5039</td> <td>-0.2810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>0.0253</td>   <td>0.0568</td>   <td>0.4451</td>  <td>0.6563</td> <td>-0.0861</td> <td>0.1367</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>-0.3193</td>  <td>0.0572</td>   <td>-5.5813</td> <td>0.0000</td> <td>-0.4315</td> <td>-0.2072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>-0.2408</td>  <td>0.0569</td>   <td>-4.2324</td> <td>0.0000</td> <td>-0.3523</td> <td>-0.1293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>-0.5912</td>  <td>0.0570</td>  <td>-10.3708</td> <td>0.0000</td> <td>-0.7029</td> <td>-0.4794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>-0.2219</td>  <td>0.0570</td>   <td>-3.8938</td> <td>0.0001</td> <td>-0.3335</td> <td>-0.1102</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>34604.616</td>  <td>Durbin-Watson:</td>       <td>1.994</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td>   <td>0.000</td>   <td>Jarque-Bera (JB):</td> <td>10667752.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>       <td>4.483</td>       <td>Prob(JB):</td>         <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>    <td>89.455</td>    <td>Condition No.:</td>         <td>3</td>     \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                  Results: Ordinary least squares\n",
       "====================================================================\n",
       "Model:              OLS              Adj. R-squared:     0.041      \n",
       "Dependent Variable: pct_d_rgdp       AIC:                246977.3317\n",
       "Date:               2021-02-25 14:24 BIC:                247196.5337\n",
       "No. Observations:   33889            Log-Likelihood:     -1.2346e+05\n",
       "Df Model:           25               F-statistic:        58.31      \n",
       "Df Residuals:       33863            Prob (F-statistic): 4.48e-286  \n",
       "R-squared:          0.041            Scale:              85.557     \n",
       "--------------------------------------------------------------------\n",
       "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "--------------------------------------------------------------------\n",
       "const                1.9833   0.0502  39.4717 0.0000  1.8848  2.0818\n",
       "pos_net_jobs         0.5576   0.0542  10.2891 0.0000  0.4514  0.6638\n",
       "emp_estabs          -0.1799   0.0543  -3.3099 0.0009 -0.2864 -0.0733\n",
       "estabs_entry_rate    0.8986   0.0597  15.0624 0.0000  0.7817  1.0155\n",
       "estabs_exit_rate    -0.5245   0.0579  -9.0616 0.0000 -0.6380 -0.4111\n",
       "pop                 -0.1051   0.0567  -1.8529 0.0639 -0.2164  0.0061\n",
       "pop_pct_black        0.0231   0.0573   0.4031 0.6869 -0.0893  0.1355\n",
       "pop_pct_hisp         0.3096   0.0522   5.9342 0.0000  0.2073  0.4118\n",
       "lfpr                 0.4921   0.0624   7.8888 0.0000  0.3698  0.6144\n",
       "density             -0.0089   0.0540  -0.1646 0.8693 -0.1147  0.0969\n",
       "lower                0.6103   0.0684   8.9266 0.0000  0.4763  0.7443\n",
       "similar              0.2587   0.0590   4.3821 0.0000  0.1430  0.3745\n",
       "2004                -0.0797   0.0565  -1.4104 0.1584 -0.1904  0.0310\n",
       "2005                 0.0635   0.0603   1.0525 0.2926 -0.0547  0.1816\n",
       "2006                 0.4367   0.0613   7.1289 0.0000  0.3166  0.5568\n",
       "2007                -0.3333   0.0566  -5.8880 0.0000 -0.4442 -0.2223\n",
       "2008                -0.3639   0.0566  -6.4307 0.0000 -0.4748 -0.2530\n",
       "2009                -0.5530   0.0580  -9.5330 0.0000 -0.6668 -0.4393\n",
       "2010                 0.1662   0.0571   2.9088 0.0036  0.0542  0.2782\n",
       "2011                -0.0976   0.0569  -1.7135 0.0866 -0.2092  0.0140\n",
       "2012                -0.3924   0.0569  -6.8997 0.0000 -0.5039 -0.2810\n",
       "2013                 0.0253   0.0568   0.4451 0.6563 -0.0861  0.1367\n",
       "2014                -0.3193   0.0572  -5.5813 0.0000 -0.4315 -0.2072\n",
       "2015                -0.2408   0.0569  -4.2324 0.0000 -0.3523 -0.1293\n",
       "2016                -0.5912   0.0570 -10.3708 0.0000 -0.7029 -0.4794\n",
       "2017                -0.2219   0.0570  -3.8938 0.0001 -0.3335 -0.1102\n",
       "--------------------------------------------------------------------\n",
       "Omnibus:            34604.616     Durbin-Watson:        1.994       \n",
       "Prob(Omnibus):      0.000         Jarque-Bera (JB):     10667752.888\n",
       "Skew:               4.483         Prob(JB):             0.000       \n",
       "Kurtosis:           89.455        Condition No.:        3           \n",
       "====================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_std_final = sm.OLS(y_train, x_train_std_trim).fit()\n",
    "fit_std_final.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trim = x_train.loc[:, ~x_train.columns.isin(beta.index[beta == 0])]\n",
    "x_test_trim = x_test.loc[:, ~x_test.columns.isin(beta.index[beta == 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>      <td>0.041</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>pct_d_rgdp</td>           <td>AIC:</td>         <td>246977.3317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-02-25 14:24</td>        <td>BIC:</td>         <td>247196.5337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33889</td>        <td>Log-Likelihood:</td>   <td>-1.2346e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>25</td>           <td>F-statistic:</td>        <td>58.31</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33863</td>      <td>Prob (F-statistic):</td>  <td>4.48e-286</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.041</td>            <td>Scale:</td>          <td>85.557</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-2.6168</td>  <td>0.5422</td>   <td>-4.8265</td> <td>0.0000</td> <td>-3.6795</td> <td>-1.5541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>1.1235</td>   <td>0.1092</td>   <td>10.2891</td> <td>0.0000</td> <td>0.9094</td>  <td>1.3375</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>-0.0377</td>  <td>0.0114</td>   <td>-3.3099</td> <td>0.0009</td> <td>-0.0600</td> <td>-0.0154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.2968</td>   <td>0.0197</td>   <td>15.0624</td> <td>0.0000</td> <td>0.2582</td>  <td>0.3355</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.2050</td>  <td>0.0226</td>   <td>-9.0616</td> <td>0.0000</td> <td>-0.2493</td> <td>-0.1607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-0.0000</td>  <td>0.0000</td>   <td>-1.8529</td> <td>0.0639</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>0.0016</td>   <td>0.0039</td>   <td>0.4031</td>  <td>0.6869</td> <td>-0.0061</td> <td>0.0093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.0236</td>   <td>0.0040</td>   <td>5.9342</td>  <td>0.0000</td> <td>0.0158</td>  <td>0.0314</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.0441</td>   <td>0.0056</td>   <td>7.8888</td>  <td>0.0000</td> <td>0.0332</td>  <td>0.0551</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>-0.0000</td>  <td>0.0000</td>   <td>-0.1646</td> <td>0.8693</td> <td>-0.0001</td> <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>1.2577</td>   <td>0.1409</td>   <td>8.9266</td>  <td>0.0000</td> <td>0.9815</td>  <td>1.5338</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.6687</td>   <td>0.1526</td>   <td>4.3821</td>  <td>0.0000</td> <td>0.3696</td>  <td>0.9678</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>-0.3401</td>  <td>0.2411</td>   <td>-1.4104</td> <td>0.1584</td> <td>-0.8126</td> <td>0.1325</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>0.2685</td>   <td>0.2551</td>   <td>1.0525</td>  <td>0.2926</td> <td>-0.2315</td> <td>0.7686</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>1.8407</td>   <td>0.2582</td>   <td>7.1289</td>  <td>0.0000</td> <td>1.3346</td>  <td>2.3468</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>-1.4058</td>  <td>0.2388</td>   <td>-5.8880</td> <td>0.0000</td> <td>-1.8738</td> <td>-0.9378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>-1.5510</td>  <td>0.2412</td>   <td>-6.4307</td> <td>0.0000</td> <td>-2.0237</td> <td>-1.0783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-2.3392</td>  <td>0.2454</td>   <td>-9.5330</td> <td>0.0000</td> <td>-2.8201</td> <td>-1.8582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>0.7026</td>   <td>0.2415</td>   <td>2.9088</td>  <td>0.0036</td> <td>0.2291</td>  <td>1.1760</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>-0.4109</td>  <td>0.2398</td>   <td>-1.7135</td> <td>0.0866</td> <td>-0.8809</td> <td>0.0591</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>-1.6752</td>  <td>0.2428</td>   <td>-6.8997</td> <td>0.0000</td> <td>-2.1510</td> <td>-1.1993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>0.1077</td>   <td>0.2420</td>   <td>0.4451</td>  <td>0.6563</td> <td>-0.3667</td> <td>0.5821</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>-1.3413</td>  <td>0.2403</td>   <td>-5.5813</td> <td>0.0000</td> <td>-1.8123</td> <td>-0.8703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>-1.0404</td>  <td>0.2458</td>   <td>-4.2324</td> <td>0.0000</td> <td>-1.5222</td> <td>-0.5586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>-2.5181</td>  <td>0.2428</td>  <td>-10.3708</td> <td>0.0000</td> <td>-2.9940</td> <td>-2.0422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>-0.9448</td>  <td>0.2426</td>   <td>-3.8938</td> <td>0.0001</td> <td>-1.4203</td> <td>-0.4692</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>34604.616</td>  <td>Durbin-Watson:</td>       <td>1.994</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td>   <td>0.000</td>   <td>Jarque-Bera (JB):</td> <td>10667752.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>       <td>4.483</td>       <td>Prob(JB):</td>         <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>    <td>89.455</td>    <td>Condition No.:</td>      <td>3896078</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                  Results: Ordinary least squares\n",
       "====================================================================\n",
       "Model:              OLS              Adj. R-squared:     0.041      \n",
       "Dependent Variable: pct_d_rgdp       AIC:                246977.3317\n",
       "Date:               2021-02-25 14:24 BIC:                247196.5337\n",
       "No. Observations:   33889            Log-Likelihood:     -1.2346e+05\n",
       "Df Model:           25               F-statistic:        58.31      \n",
       "Df Residuals:       33863            Prob (F-statistic): 4.48e-286  \n",
       "R-squared:          0.041            Scale:              85.557     \n",
       "--------------------------------------------------------------------\n",
       "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "--------------------------------------------------------------------\n",
       "const               -2.6168   0.5422  -4.8265 0.0000 -3.6795 -1.5541\n",
       "pos_net_jobs         1.1235   0.1092  10.2891 0.0000  0.9094  1.3375\n",
       "emp_estabs          -0.0377   0.0114  -3.3099 0.0009 -0.0600 -0.0154\n",
       "estabs_entry_rate    0.2968   0.0197  15.0624 0.0000  0.2582  0.3355\n",
       "estabs_exit_rate    -0.2050   0.0226  -9.0616 0.0000 -0.2493 -0.1607\n",
       "pop                 -0.0000   0.0000  -1.8529 0.0639 -0.0000  0.0000\n",
       "pop_pct_black        0.0016   0.0039   0.4031 0.6869 -0.0061  0.0093\n",
       "pop_pct_hisp         0.0236   0.0040   5.9342 0.0000  0.0158  0.0314\n",
       "lfpr                 0.0441   0.0056   7.8888 0.0000  0.0332  0.0551\n",
       "density             -0.0000   0.0000  -0.1646 0.8693 -0.0001  0.0001\n",
       "lower                1.2577   0.1409   8.9266 0.0000  0.9815  1.5338\n",
       "similar              0.6687   0.1526   4.3821 0.0000  0.3696  0.9678\n",
       "2004                -0.3401   0.2411  -1.4104 0.1584 -0.8126  0.1325\n",
       "2005                 0.2685   0.2551   1.0525 0.2926 -0.2315  0.7686\n",
       "2006                 1.8407   0.2582   7.1289 0.0000  1.3346  2.3468\n",
       "2007                -1.4058   0.2388  -5.8880 0.0000 -1.8738 -0.9378\n",
       "2008                -1.5510   0.2412  -6.4307 0.0000 -2.0237 -1.0783\n",
       "2009                -2.3392   0.2454  -9.5330 0.0000 -2.8201 -1.8582\n",
       "2010                 0.7026   0.2415   2.9088 0.0036  0.2291  1.1760\n",
       "2011                -0.4109   0.2398  -1.7135 0.0866 -0.8809  0.0591\n",
       "2012                -1.6752   0.2428  -6.8997 0.0000 -2.1510 -1.1993\n",
       "2013                 0.1077   0.2420   0.4451 0.6563 -0.3667  0.5821\n",
       "2014                -1.3413   0.2403  -5.5813 0.0000 -1.8123 -0.8703\n",
       "2015                -1.0404   0.2458  -4.2324 0.0000 -1.5222 -0.5586\n",
       "2016                -2.5181   0.2428 -10.3708 0.0000 -2.9940 -2.0422\n",
       "2017                -0.9448   0.2426  -3.8938 0.0001 -1.4203 -0.4692\n",
       "--------------------------------------------------------------------\n",
       "Omnibus:            34604.616     Durbin-Watson:        1.994       \n",
       "Prob(Omnibus):      0.000         Jarque-Bera (JB):     10667752.888\n",
       "Skew:               4.483         Prob(JB):             0.000       \n",
       "Kurtosis:           89.455        Condition No.:        3896078     \n",
       "====================================================================\n",
       "* The condition number is large (4e+06). This might indicate\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_final = sm.OLS(y_train, x_train_trim).fit()\n",
    "fit_final.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Lastly, we will test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.403229309446852"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_null = np.sqrt(np.mean(  (y_test - np.mean(y_train))**2  ))\n",
    "rmse_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.216937110787729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.98"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lasso = np.sqrt(np.mean(  (y_test - fit_lasso_tuned.predict(x_test_std))**2  ))\n",
    "print(rmse_lasso)\n",
    "round((rmse_lasso - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.216949429609352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.98"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_std_final = np.sqrt(np.mean(  (y_test - fit_std_final.predict(x_test_std_trim))**2  ))\n",
    "print(rmse_std_final)\n",
    "round((rmse_std_final - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.21691435737444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_final = np.sqrt(np.mean(  (y_test - fit_final.predict(x_test_trim))**2  ))\n",
    "print(rmse_final)\n",
    "round((rmse_final - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward selection gave us a 1.37% reduction in RMSE. \n",
    "\n",
    "# What does ^ tell you about statistical significance for predictive power?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
