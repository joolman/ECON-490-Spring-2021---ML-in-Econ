{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression-Based Classification\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "* [Preliminaries](#Preliminaries)\n",
    "* [Binomial Logistic Regression](#Binomial-Logistic-Regression)\n",
    "    - [Logit Inference](#Logit-Inference)\n",
    "        - [Logit Marginal Effects](#Logit-Marginal-Effects)\n",
    "        - [Comparison to LPM](#Comparison-to-LPM)\n",
    "        - [Logit Regularization](#Logit-Regularization)\n",
    "    - [Logit Prediction Diagnostics](#Logit-Prediction-Diagnostics)\n",
    "        - [Logit Null Model](#Logit-Null-Model)\n",
    "        - [Logit Full Model](#Logit-Full-Model)\n",
    "        - [Alternative Thresholds](#Alternative-Thresholds)\n",
    "- [Multinomial Logistic Regression](#Multinomial-Logistic-Regression)\n",
    "    - [MN Logit Inference](#MN-Logit-Inference)\n",
    "        - [MN Logit Marginal Effects](#MN-Logit-Marginal-Effects)\n",
    "        - [MN Logit Regularization](#MN-Logit-Regularization)\n",
    "    - [MN Logit Prediction Diagnostics](#MN-Logit-Prediction-Diagnostics)\n",
    "        - [MN Logit Null Model](#MN-Logit-Null-Model)\n",
    "        - [MN Logit Full Model](#MN-Logit-Full-Model)\n",
    "\n",
    "***\n",
    "# Preliminaries\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'axes.titlesize': 24,\n",
    "             'axes.labelsize': 20,\n",
    "             'xtick.labelsize': 12,\n",
    "             'ytick.labelsize': 12,\n",
    "             'figure.figsize': (8, 4.5)})\n",
    "sns.set_style(\"white\") # for plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['urate_bin', 'year']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df.year, drop_first = True)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['pos_net_jobs'].astype(float)\n",
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "# Binomial Logistic Regression\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "There are three primary ways to fit a logsitic regression:\n",
    "\n",
    "- `statsmodels.api.Logit(y, x).fit()`\n",
    "- `statsmodels.formula.api.logit(data = df, formula = 'y ~ x').fit()`\n",
    "- `sklearn.linear_model.LogisticRegression().fit(x, y)`\n",
    "\n",
    "************\n",
    "## Logit Inference\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "By now, if you are thinking inference, then you should be thinking `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599666\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "fit_logit = sm.Logit(y_train, x_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.126</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>   <td>pos_net_jobs</td>         <td>AIC:</td>        <td>40700.1748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:19</td>       <td>BIC:</td>        <td>40936.2385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33889</td>       <td>Log-Likelihood:</td>    <td>-20322.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>27</td>            <td>LL-Null:</td>        <td>-23242.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33861</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-1.9804</td>  <td>0.1454</td>  <td>-13.6244</td> <td>0.0000</td> <td>-2.2653</td> <td>-1.6955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>0.0159</td>   <td>0.0014</td>   <td>11.0808</td> <td>0.0000</td> <td>0.0131</td>  <td>0.0187</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>0.0383</td>   <td>0.0029</td>   <td>13.2672</td> <td>0.0000</td> <td>0.0327</td>  <td>0.0440</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.1938</td>   <td>0.0054</td>   <td>35.7595</td> <td>0.0000</td> <td>0.1832</td>  <td>0.2045</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.1625</td>  <td>0.0060</td>  <td>-27.1367</td> <td>0.0000</td> <td>-0.1743</td> <td>-0.1508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>0.0000</td>   <td>0.0000</td>   <td>2.7815</td>  <td>0.0054</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>-0.0037</td>  <td>0.0009</td>   <td>-3.9538</td> <td>0.0001</td> <td>-0.0055</td> <td>-0.0019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.0065</td>   <td>0.0010</td>   <td>6.6630</td>  <td>0.0000</td> <td>0.0046</td>  <td>0.0084</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.0014</td>   <td>0.0014</td>   <td>1.0370</td>  <td>0.2997</td> <td>-0.0012</td> <td>0.0041</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>0.0000</td>   <td>0.0000</td>   <td>0.8976</td>  <td>0.3694</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>0.3427</td>   <td>0.0335</td>   <td>10.2204</td> <td>0.0000</td> <td>0.2770</td>  <td>0.4084</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.1708</td>   <td>0.0357</td>   <td>4.7822</td>  <td>0.0000</td> <td>0.1008</td>  <td>0.2408</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>1.0795</td>   <td>0.0685</td>   <td>15.7513</td> <td>0.0000</td> <td>0.9451</td>  <td>1.2138</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>1.2705</td>   <td>0.0701</td>   <td>18.1212</td> <td>0.0000</td> <td>1.1330</td>  <td>1.4079</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>1.2782</td>   <td>0.0718</td>   <td>17.7988</td> <td>0.0000</td> <td>1.1374</td>  <td>1.4189</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>1.7408</td>   <td>0.0752</td>   <td>23.1429</td> <td>0.0000</td> <td>1.5934</td>  <td>1.8882</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>0.5726</td>   <td>0.0679</td>   <td>8.4340</td>  <td>0.0000</td> <td>0.4396</td>  <td>0.7057</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>0.9002</td>   <td>0.0689</td>   <td>13.0671</td> <td>0.0000</td> <td>0.7652</td>  <td>1.0353</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-0.5546</td>  <td>0.0813</td>   <td>-6.8221</td> <td>0.0000</td> <td>-0.7139</td> <td>-0.3953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>0.1881</td>   <td>0.0712</td>   <td>2.6427</td>  <td>0.0082</td> <td>0.0486</td>  <td>0.3275</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>1.2499</td>   <td>0.0694</td>   <td>18.0167</td> <td>0.0000</td> <td>1.1139</td>  <td>1.3858</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>1.5995</td>   <td>0.0719</td>   <td>22.2615</td> <td>0.0000</td> <td>1.4587</td>  <td>1.7404</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>1.2136</td>   <td>0.0701</td>   <td>17.3026</td> <td>0.0000</td> <td>1.0762</td>  <td>1.3511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>1.5303</td>   <td>0.0716</td>   <td>21.3646</td> <td>0.0000</td> <td>1.3899</td>  <td>1.6707</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>1.6389</td>   <td>0.0738</td>   <td>22.2195</td> <td>0.0000</td> <td>1.4944</td>  <td>1.7835</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>1.2858</td>   <td>0.0714</td>   <td>18.0141</td> <td>0.0000</td> <td>1.1459</td>  <td>1.4257</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>1.1100</td>   <td>0.0703</td>   <td>15.7814</td> <td>0.0000</td> <td>0.9721</td>  <td>1.2478</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2018</th>              <td>1.4769</td>   <td>0.0726</td>   <td>20.3342</td> <td>0.0000</td> <td>1.3346</td>  <td>1.6193</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:               Logit            Pseudo R-squared: 0.126     \n",
       "Dependent Variable:  pos_net_jobs     AIC:              40700.1748\n",
       "Date:                2021-03-02 14:19 BIC:              40936.2385\n",
       "No. Observations:    33889            Log-Likelihood:   -20322.   \n",
       "Df Model:            27               LL-Null:          -23242.   \n",
       "Df Residuals:        33861            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "const             -1.9804   0.1454 -13.6244 0.0000 -2.2653 -1.6955\n",
       "pct_d_rgdp         0.0159   0.0014  11.0808 0.0000  0.0131  0.0187\n",
       "emp_estabs         0.0383   0.0029  13.2672 0.0000  0.0327  0.0440\n",
       "estabs_entry_rate  0.1938   0.0054  35.7595 0.0000  0.1832  0.2045\n",
       "estabs_exit_rate  -0.1625   0.0060 -27.1367 0.0000 -0.1743 -0.1508\n",
       "pop                0.0000   0.0000   2.7815 0.0054  0.0000  0.0000\n",
       "pop_pct_black     -0.0037   0.0009  -3.9538 0.0001 -0.0055 -0.0019\n",
       "pop_pct_hisp       0.0065   0.0010   6.6630 0.0000  0.0046  0.0084\n",
       "lfpr               0.0014   0.0014   1.0370 0.2997 -0.0012  0.0041\n",
       "density            0.0000   0.0000   0.8976 0.3694 -0.0000  0.0000\n",
       "lower              0.3427   0.0335  10.2204 0.0000  0.2770  0.4084\n",
       "similar            0.1708   0.0357   4.7822 0.0000  0.1008  0.2408\n",
       "2003               1.0795   0.0685  15.7513 0.0000  0.9451  1.2138\n",
       "2004               1.2705   0.0701  18.1212 0.0000  1.1330  1.4079\n",
       "2005               1.2782   0.0718  17.7988 0.0000  1.1374  1.4189\n",
       "2006               1.7408   0.0752  23.1429 0.0000  1.5934  1.8882\n",
       "2007               0.5726   0.0679   8.4340 0.0000  0.4396  0.7057\n",
       "2008               0.9002   0.0689  13.0671 0.0000  0.7652  1.0353\n",
       "2009              -0.5546   0.0813  -6.8221 0.0000 -0.7139 -0.3953\n",
       "2010               0.1881   0.0712   2.6427 0.0082  0.0486  0.3275\n",
       "2011               1.2499   0.0694  18.0167 0.0000  1.1139  1.3858\n",
       "2012               1.5995   0.0719  22.2615 0.0000  1.4587  1.7404\n",
       "2013               1.2136   0.0701  17.3026 0.0000  1.0762  1.3511\n",
       "2014               1.5303   0.0716  21.3646 0.0000  1.3899  1.6707\n",
       "2015               1.6389   0.0738  22.2195 0.0000  1.4944  1.7835\n",
       "2016               1.2858   0.0714  18.0141 0.0000  1.1459  1.4257\n",
       "2017               1.1100   0.0703  15.7814 0.0000  0.9721  1.2478\n",
       "2018               1.4769   0.0726  20.3342 0.0000  1.3346  1.6193\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n",
    "### Logit Marginal Effects \n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>pos_net_jobs</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>            <td>dydx</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>               <td>overall</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <th></th>             <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>    0.0033</td> <td>    0.000</td> <td>   11.150</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0079</td> <td>    0.001</td> <td>   13.394</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>    0.0401</td> <td>    0.001</td> <td>   38.375</td> <td> 0.000</td> <td>    0.038</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0336</td> <td>    0.001</td> <td>  -28.236</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td> 3.029e-08</td> <td> 1.09e-08</td> <td>    2.782</td> <td> 0.005</td> <td> 8.95e-09</td> <td> 5.16e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0008</td> <td>    0.000</td> <td>   -3.957</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>    0.0013</td> <td>    0.000</td> <td>    6.678</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>    0.0003</td> <td>    0.000</td> <td>    1.037</td> <td> 0.300</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>  1.59e-06</td> <td> 1.77e-06</td> <td>    0.898</td> <td> 0.369</td> <td>-1.88e-06</td> <td> 5.06e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>    0.0709</td> <td>    0.007</td> <td>   10.278</td> <td> 0.000</td> <td>    0.057</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>    0.0353</td> <td>    0.007</td> <td>    4.788</td> <td> 0.000</td> <td>    0.021</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>    0.2232</td> <td>    0.014</td> <td>   15.973</td> <td> 0.000</td> <td>    0.196</td> <td>    0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>    0.2627</td> <td>    0.014</td> <td>   18.459</td> <td> 0.000</td> <td>    0.235</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>    0.2643</td> <td>    0.015</td> <td>   18.120</td> <td> 0.000</td> <td>    0.236</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>    0.3600</td> <td>    0.015</td> <td>   23.839</td> <td> 0.000</td> <td>    0.330</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>    0.1184</td> <td>    0.014</td> <td>    8.467</td> <td> 0.000</td> <td>    0.091</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>    0.1862</td> <td>    0.014</td> <td>   13.189</td> <td> 0.000</td> <td>    0.159</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>   -0.1147</td> <td>    0.017</td> <td>   -6.834</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>    0.0389</td> <td>    0.015</td> <td>    2.644</td> <td> 0.008</td> <td>    0.010</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>    0.2585</td> <td>    0.014</td> <td>   18.345</td> <td> 0.000</td> <td>    0.231</td> <td>    0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>    0.3308</td> <td>    0.014</td> <td>   22.889</td> <td> 0.000</td> <td>    0.302</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>    0.2510</td> <td>    0.014</td> <td>   17.594</td> <td> 0.000</td> <td>    0.223</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>    0.3165</td> <td>    0.014</td> <td>   21.919</td> <td> 0.000</td> <td>    0.288</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>    0.3389</td> <td>    0.015</td> <td>   22.840</td> <td> 0.000</td> <td>    0.310</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>    0.2659</td> <td>    0.014</td> <td>   18.345</td> <td> 0.000</td> <td>    0.238</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>    0.2295</td> <td>    0.014</td> <td>   16.001</td> <td> 0.000</td> <td>    0.201</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2018</th>              <td>    0.3054</td> <td>    0.015</td> <td>   20.812</td> <td> 0.000</td> <td>    0.277</td> <td>    0.334</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:           pos_net_jobs\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "=====================================================================================\n",
       "                       dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp            0.0033      0.000     11.150      0.000       0.003       0.004\n",
       "emp_estabs            0.0079      0.001     13.394      0.000       0.007       0.009\n",
       "estabs_entry_rate     0.0401      0.001     38.375      0.000       0.038       0.042\n",
       "estabs_exit_rate     -0.0336      0.001    -28.236      0.000      -0.036      -0.031\n",
       "pop                3.029e-08   1.09e-08      2.782      0.005    8.95e-09    5.16e-08\n",
       "pop_pct_black        -0.0008      0.000     -3.957      0.000      -0.001      -0.000\n",
       "pop_pct_hisp          0.0013      0.000      6.678      0.000       0.001       0.002\n",
       "lfpr                  0.0003      0.000      1.037      0.300      -0.000       0.001\n",
       "density             1.59e-06   1.77e-06      0.898      0.369   -1.88e-06    5.06e-06\n",
       "lower                 0.0709      0.007     10.278      0.000       0.057       0.084\n",
       "similar               0.0353      0.007      4.788      0.000       0.021       0.050\n",
       "2003                  0.2232      0.014     15.973      0.000       0.196       0.251\n",
       "2004                  0.2627      0.014     18.459      0.000       0.235       0.291\n",
       "2005                  0.2643      0.015     18.120      0.000       0.236       0.293\n",
       "2006                  0.3600      0.015     23.839      0.000       0.330       0.390\n",
       "2007                  0.1184      0.014      8.467      0.000       0.091       0.146\n",
       "2008                  0.1862      0.014     13.189      0.000       0.159       0.214\n",
       "2009                 -0.1147      0.017     -6.834      0.000      -0.148      -0.082\n",
       "2010                  0.0389      0.015      2.644      0.008       0.010       0.068\n",
       "2011                  0.2585      0.014     18.345      0.000       0.231       0.286\n",
       "2012                  0.3308      0.014     22.889      0.000       0.302       0.359\n",
       "2013                  0.2510      0.014     17.594      0.000       0.223       0.279\n",
       "2014                  0.3165      0.014     21.919      0.000       0.288       0.345\n",
       "2015                  0.3389      0.015     22.840      0.000       0.310       0.368\n",
       "2016                  0.2659      0.014     18.345      0.000       0.238       0.294\n",
       "2017                  0.2295      0.014     16.001      0.000       0.201       0.258\n",
       "2018                  0.3054      0.015     20.812      0.000       0.277       0.334\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no summary2() method for marginal effects\n",
    "fit_logit.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "### Comparison to LPM \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "For the sake of not exploding this notebook with summaries, let's use a simplier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670597\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>pos_net_jobs</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>            <td>dydx</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>               <td>overall</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <th></th>            <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>       <td>    0.0057</td> <td>    0.000</td> <td>   17.597</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th> <td>   -0.0280</td> <td>    0.001</td> <td>  -26.347</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:           pos_net_jobs\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "====================================================================================\n",
       "                      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           0.0057      0.000     17.597      0.000       0.005       0.006\n",
       "estabs_exit_rate    -0.0280      0.001    -26.347      0.000      -0.030      -0.026\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.Logit(y_train, x_train[['const', 'pct_d_rgdp', 'estabs_exit_rate']]).fit().get_margeff().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const               0.791239\n",
       "pct_d_rgdp          0.004881\n",
       "estabs_exit_rate   -0.027172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(y_train, x_train[['const', 'pct_d_rgdp', 'estabs_exit_rate']]).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these values are not identical, they are pretty close to one another. This is because OLS is always a first order approximation. Think/thank Taylor Series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "### Logit Regularization \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We can also perform regularization, much like OLS:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lm.LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'l1_ratio': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.arange(-5, -1, step = 1),\n",
    "    'l1_ratio':  np.arange(0, 1, step = 0.1)\n",
    "}\n",
    "\n",
    "lr_cv = lm.LogisticRegression(penalty = 'elasticnet', solver = 'saga',\n",
    "                              max_iter = 1e3, random_state = 490)\n",
    "grid_search = GridSearchCV(lr_cv, param_grid, \n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = 10)\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $C = \\frac{1}{\\alpha}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6148664747464858\n",
      "            Iterations: 46\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                0.242299\n",
       "pct_d_rgdp           0.129515\n",
       "emp_estabs           0.160000\n",
       "estabs_entry_rate    0.524969\n",
       "estabs_exit_rate    -0.409562\n",
       "pop                  0.044251\n",
       "pop_pct_black       -0.043049\n",
       "pop_pct_hisp         0.080563\n",
       "lfpr                 0.011502\n",
       "density              0.002602\n",
       "lower                0.132604\n",
       "similar              0.035284\n",
       "2003                 0.102634\n",
       "2004                 0.144029\n",
       "2005                 0.138147\n",
       "2006                 0.250307\n",
       "2007                 0.000000\n",
       "2008                 0.053639\n",
       "2009                -0.260567\n",
       "2010                -0.091555\n",
       "2011                 0.132870\n",
       "2012                 0.210276\n",
       "2013                 0.123378\n",
       "2014                 0.198359\n",
       "2015                 0.217663\n",
       "2016                 0.140723\n",
       "2017                 0.099798\n",
       "2018                 0.180612\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will get convergence warnings\n",
    "# They are due to difficulty converging\n",
    "# We can address this by accepting some error\n",
    "# with our qc_tol\n",
    "# See below\n",
    "fit_logit_reg = sm.Logit(y_train, x_train_std\n",
    "                        ).fit_regularized(alpha = 1/best['C'],\n",
    "                                          L1_wt = best['l1_ratio'],\n",
    "                                          qc_tol = 1e3)\n",
    "fit_logit_reg.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "## Logit Prediction Diagnostics\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "Here we are going to look at how to produce\n",
    "\n",
    "- accuracy\n",
    "- visualizing optimal threshold values\n",
    "- the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16945.000000\n",
       "mean         0.562920\n",
       "std          0.197952\n",
       "min          0.000070\n",
       "25%          0.440244\n",
       "50%          0.595493\n",
       "75%          0.712055\n",
       "max          0.999784\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.predict(x_test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the summary of `yhat`, `statsmodels` predicts the probabilities. **How do we know that to be true?**\n",
    "\n",
    "***\n",
    "\n",
    "To produce the **prediction** diagnostics, it is easier to use `sklearn`. \n",
    "\n",
    "********\n",
    "### Logit Null Model\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "In classification, the **null model** is simply predicting the most frequently occuring class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    18992\n",
       "0.0    14897\n",
       "Name: pos_net_jobs, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564886397167306"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_logit_null = np.mean(y_test == 1)\n",
    "acc_logit_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### Logit Full Model\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "For the sake of exposition, we are simply going to use all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logit_sk = lm.LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = fit_logit_sk.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6076128651519622"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_logit = np.mean(yhat == y_test)\n",
    "acc_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.563727538654397"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_logit - acc_logit_null)/acc_logit_null*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(fit_logit_sk, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have to consider changing thresholds.\n",
    "\n",
    "***\n",
    "### Alternative Thresholds\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We can use `sklearn` to predict probabilities. \n",
    "It will produce a column for each class you have.\n",
    "In this case, we have two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26809485, 0.73190515],\n",
       "       [0.45851187, 0.54148813],\n",
       "       [0.43310779, 0.56689221],\n",
       "       [0.29880253, 0.70119747],\n",
       "       [0.50159124, 0.49840876]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_proba = fit_logit_sk.predict_proba(x_test)\n",
    "yhat_proba[range(5), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07673719653613793"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(yhat_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum probability of being in a county with positive net job creation is greater than the default threshold of 50%! Indeed! We will have to cross-validate the threshold.\n",
    "\n",
    "There is no built in function to cross-validate the threshold for logit. \n",
    "We will have to manually set up the loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(y_train, x_train, left_index = True, right_index = True)\n",
    "kf = KFold(n_splits = 5, random_state = 490, shuffle = True)\n",
    "alpha = np.round(    np.arange(0.5, 0.7, step = 0.01), 2    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:23<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.5: 0.5742573567679164,\n",
       " 0.51: 0.5788901093221728,\n",
       " 0.52: 0.5847327976053558,\n",
       " 0.53: 0.5912540955594471,\n",
       " 0.54: 0.5949130268212747,\n",
       " 0.55: 0.5897785555808525,\n",
       " 0.56: 0.5738736582907847,\n",
       " 0.57: 0.5469327524715297,\n",
       " 0.58: 0.5242114979967347,\n",
       " 0.59: 0.5037035382507433,\n",
       " 0.6: 0.4908084044704868,\n",
       " 0.61: 0.48180843830126313,\n",
       " 0.62: 0.47428392938415403,\n",
       " 0.63: 0.4685298629313658,\n",
       " 0.64: 0.46404455944295997,\n",
       " 0.65: 0.46065109745601707,\n",
       " 0.66: 0.45699206605160836,\n",
       " 0.67: 0.4541592327127672,\n",
       " 0.68: 0.45247725097990604,\n",
       " 0.69: 0.4505002230784848}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = {}\n",
    "\n",
    "for a in tqdm(alpha):\n",
    "    acc = []\n",
    "    for trn, tst in kf.split(train):\n",
    "        yhat = (lm.LogisticRegression(solver = 'liblinear'\n",
    "                                      ).fit(train.iloc[trn, 1:], train.iloc[trn, 0]\n",
    "                                           ).predict_proba(train.iloc[tst, 1:])[:, 1] > a)*1\n",
    "        acc.append(np.mean(yhat == train.iloc[tst, 0]))\n",
    "    accuracy[a] = np.mean(acc)\n",
    "    \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy at alpha = 0.54\n"
     ]
    }
   ],
   "source": [
    "print('max accuracy at alpha = %s' % max(accuracy, key = accuracy.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(accuracy.keys(), accuracy.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum is $\\alpha=0.54$. However, from the figure, it looks like we can choose either 0.54 or 0.55. Since the accuracy drops off quickly to the right, we may be safer using 0.54.\n",
    "\n",
    "Because we have adjusted the threshold, we need to manually calculate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3630 3743]\n",
      " [2858 6714]]\n",
      "0.6104455591619947\n",
      "0.6104455591619947 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_alpha = max(accuracy, key = accuracy.get)\n",
    "yhat_class = (yhat_proba[:, 1] >= best_alpha)*1\n",
    "\n",
    "TN = sum(((y_test == yhat_class) & (y_test == 0))*1)\n",
    "FP = sum(((y_test != yhat_class) & (y_test == 0))*1)\n",
    "FN = sum(((y_test != yhat_class) & (y_test == 1))*1)\n",
    "TP = sum(((y_test == yhat_class) & (y_test == 1))*1)\n",
    "\n",
    "print(np.array([[TN, FP],[FN, TP]]))\n",
    "print((TN + TP)/(TN + FN + FP + TP))\n",
    "acc_logit_54 = np.mean(yhat_class == y_test)\n",
    "print(acc_logit_54, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the percent improvement from the null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.07"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(  (acc_logit_54 - acc_logit_null)/acc_logit_null*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks we have improved our prediction by just over 8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "# Multinomial Logistic Regression \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We need to adjust features and labels to retreive our multiclass label. It is easier to start from scratch. \n",
    "\n",
    "Because logisitc functions struggle with many dummy variables, we are going to simply drop the fixed effects.\n",
    "\n",
    "We will be converting the categorical label to a `category` type of object prior to splitting. This is to ensure consistent labels in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 50834 entries, (1001, 2002, 'Autauga, AL') to (56045, 2018, 'Weston, WY')\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   pct_d_rgdp         50834 non-null  float64 \n",
      " 1   urate_bin          50834 non-null  category\n",
      " 2   pos_net_jobs       50834 non-null  int32   \n",
      " 3   emp_estabs         50834 non-null  float64 \n",
      " 4   estabs_entry_rate  50834 non-null  float64 \n",
      " 5   estabs_exit_rate   50834 non-null  float64 \n",
      " 6   pop                50834 non-null  float64 \n",
      " 7   pop_pct_black      50834 non-null  float64 \n",
      " 8   pop_pct_hisp       50834 non-null  float64 \n",
      " 9   lfpr               50834 non-null  float64 \n",
      " 10  density            50834 non-null  float64 \n",
      "dtypes: category(1), float64(9), int32(1)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prepped = df.drop(columns = 'year')\n",
    "df_prepped['urate_bin'] = df_prepped['urate_bin'].astype('category')\n",
    "df_prepped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips  year  GeoName    \n",
       "1001  2002  Autauga, AL     lower\n",
       "      2003  Autauga, AL     lower\n",
       "      2004  Autauga, AL     lower\n",
       "      2005  Autauga, AL    higher\n",
       "      2006  Autauga, AL    higher\n",
       "Name: urate_bin, dtype: category\n",
       "Categories (3, object): ['higher', 'lower', 'similar']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped['urate_bin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips  year  GeoName    \n",
       "1001  2002  Autauga, AL    1\n",
       "      2003  Autauga, AL    1\n",
       "      2004  Autauga, AL    1\n",
       "      2005  Autauga, AL    0\n",
       "      2006  Autauga, AL    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped['urate_bin'].cat.codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['urate_bin']\n",
    "x = df_prepped.drop(columns = 'urate_bin')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "## MN Logit Inference\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.904853\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "fit_mnlogit = sm.MNLogit(y_train, x_train).fit(maxiter = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>             <td>MNLogit</td>     <td>Pseudo R-squared:</td>    <td>0.130</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>urate_bin</td>          <td>AIC:</td>        <td>61373.1393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:28</td>       <td>BIC:</td>        <td>61558.6179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33889</td>       <td>Log-Likelihood:</td>    <td>-30665.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>20</td>            <td>LL-Null:</td>        <td>-35259.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33867</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 0</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>-8.2408</td>  <td>0.1638</td>  <td>-50.3167</td> <td>0.0000</td> <td>-8.5618</td> <td>-7.9198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>0.0083</td>   <td>0.0015</td>   <td>5.4073</td>  <td>0.0000</td> <td>0.0053</td>  <td>0.0114</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>0.1383</td>   <td>0.0292</td>   <td>4.7272</td>  <td>0.0000</td> <td>0.0809</td>  <td>0.1956</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0155</td>   <td>0.0033</td>   <td>4.7576</td>  <td>0.0000</td> <td>0.0091</td>  <td>0.0219</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0321</td>  <td>0.0053</td>   <td>-6.0469</td> <td>0.0000</td> <td>-0.0425</td> <td>-0.0217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>-0.0957</td>  <td>0.0064</td>  <td>-14.8573</td> <td>0.0000</td> <td>-0.1083</td> <td>-0.0830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>2.0269</td>  <td>0.0427</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>-0.0153</td>  <td>0.0013</td>  <td>-11.5958</td> <td>0.0000</td> <td>-0.0179</td> <td>-0.0127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>0.0122</td>   <td>0.0011</td>   <td>11.5112</td> <td>0.0000</td> <td>0.0101</td>  <td>0.0143</td> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>0.1160</td>   <td>0.0018</td>   <td>64.9181</td> <td>0.0000</td> <td>0.1125</td>  <td>0.1195</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>1.5776</td>  <td>0.1147</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 1</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>-2.8091</td>  <td>0.1601</td>  <td>-17.5494</td> <td>0.0000</td> <td>-3.1228</td> <td>-2.4953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>0.0024</td>   <td>0.0018</td>   <td>1.3195</td>  <td>0.1870</td> <td>-0.0012</td> <td>0.0060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>0.0556</td>   <td>0.0325</td>   <td>1.7114</td>  <td>0.0870</td> <td>-0.0081</td> <td>0.1193</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0345</td>   <td>0.0034</td>   <td>10.1377</td> <td>0.0000</td> <td>0.0278</td>  <td>0.0412</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0403</td>  <td>0.0062</td>   <td>-6.5391</td> <td>0.0000</td> <td>-0.0523</td> <td>-0.0282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>-0.0638</td>  <td>0.0072</td>   <td>-8.8031</td> <td>0.0000</td> <td>-0.0780</td> <td>-0.0496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>3.8480</td>  <td>0.0001</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>-0.0095</td>  <td>0.0012</td>   <td>-8.1216</td> <td>0.0000</td> <td>-0.0117</td> <td>-0.0072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>0.0017</td>   <td>0.0013</td>   <td>1.3866</td>  <td>0.1656</td> <td>-0.0007</td> <td>0.0042</td> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>0.0333</td>   <td>0.0018</td>   <td>18.5938</td> <td>0.0000</td> <td>0.0298</td>  <td>0.0368</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>1.8199</td>  <td>0.0688</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: MNLogit\n",
       "==================================================================\n",
       "Model:               MNLogit          Pseudo R-squared: 0.130     \n",
       "Dependent Variable:  urate_bin        AIC:              61373.1393\n",
       "Date:                2021-03-02 14:28 BIC:              61558.6179\n",
       "No. Observations:    33889            Log-Likelihood:   -30665.   \n",
       "Df Model:            20               LL-Null:          -35259.   \n",
       "Df Residuals:        33867            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 0    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const -8.2408   0.1638 -50.3167 0.0000 -8.5618 -7.9198\n",
       "       pct_d_rgdp  0.0083   0.0015   5.4073 0.0000  0.0053  0.0114\n",
       "     pos_net_jobs  0.1383   0.0292   4.7272 0.0000  0.0809  0.1956\n",
       "       emp_estabs  0.0155   0.0033   4.7576 0.0000  0.0091  0.0219\n",
       "estabs_entry_rate -0.0321   0.0053  -6.0469 0.0000 -0.0425 -0.0217\n",
       " estabs_exit_rate -0.0957   0.0064 -14.8573 0.0000 -0.1083 -0.0830\n",
       "              pop  0.0000   0.0000   2.0269 0.0427  0.0000  0.0000\n",
       "    pop_pct_black -0.0153   0.0013 -11.5958 0.0000 -0.0179 -0.0127\n",
       "     pop_pct_hisp  0.0122   0.0011  11.5112 0.0000  0.0101  0.0143\n",
       "             lfpr  0.1160   0.0018  64.9181 0.0000  0.1125  0.1195\n",
       "          density  0.0000   0.0000   1.5776 0.1147 -0.0000  0.0000\n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 1    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const -2.8091   0.1601 -17.5494 0.0000 -3.1228 -2.4953\n",
       "       pct_d_rgdp  0.0024   0.0018   1.3195 0.1870 -0.0012  0.0060\n",
       "     pos_net_jobs  0.0556   0.0325   1.7114 0.0870 -0.0081  0.1193\n",
       "       emp_estabs  0.0345   0.0034  10.1377 0.0000  0.0278  0.0412\n",
       "estabs_entry_rate -0.0403   0.0062  -6.5391 0.0000 -0.0523 -0.0282\n",
       " estabs_exit_rate -0.0638   0.0072  -8.8031 0.0000 -0.0780 -0.0496\n",
       "              pop  0.0000   0.0000   3.8480 0.0001  0.0000  0.0000\n",
       "    pop_pct_black -0.0095   0.0012  -8.1216 0.0000 -0.0117 -0.0072\n",
       "     pop_pct_hisp  0.0017   0.0013   1.3866 0.1656 -0.0007  0.0042\n",
       "             lfpr  0.0333   0.0018  18.5938 0.0000  0.0298  0.0368\n",
       "          density  0.0000   0.0000   1.8199 0.0688 -0.0000  0.0000\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['higher', 'lower', 'similar'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the baseline class is 2, which is `similar`.\n",
    "\n",
    "We can change the category levels if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.904853\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>             <td>MNLogit</td>     <td>Pseudo R-squared:</td>    <td>0.130</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>urate_bin</td>          <td>AIC:</td>        <td>61373.1393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:28</td>       <td>BIC:</td>        <td>61558.6179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33889</td>       <td>Log-Likelihood:</td>    <td>-30665.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>20</td>            <td>LL-Null:</td>        <td>-35259.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33867</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 0</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>5.4318</td>   <td>0.1866</td>   <td>29.1109</td> <td>0.0000</td> <td>5.0661</td>  <td>5.7975</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>-0.0059</td>  <td>0.0019</td>   <td>-3.1928</td> <td>0.0014</td> <td>-0.0096</td> <td>-0.0023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>-0.0826</td>  <td>0.0343</td>   <td>-2.4087</td> <td>0.0160</td> <td>-0.1499</td> <td>-0.0154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0190</td>   <td>0.0035</td>   <td>5.3569</td>  <td>0.0000</td> <td>0.0121</td>  <td>0.0260</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0081</td>  <td>0.0065</td>   <td>-1.2467</td> <td>0.2125</td> <td>-0.0209</td> <td>0.0047</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>0.0319</td>   <td>0.0078</td>   <td>4.0665</td>  <td>0.0000</td> <td>0.0165</td>  <td>0.0472</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>2.0204</td>  <td>0.0433</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>0.0059</td>   <td>0.0015</td>   <td>3.8319</td>  <td>0.0001</td> <td>0.0029</td>  <td>0.0089</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>-0.0105</td>  <td>0.0013</td>   <td>-8.1890</td> <td>0.0000</td> <td>-0.0130</td> <td>-0.0080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>-0.0827</td>  <td>0.0020</td>  <td>-41.4428</td> <td>0.0000</td> <td>-0.0866</td> <td>-0.0788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>0.2440</td>  <td>0.8072</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 1</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>8.2408</td>   <td>0.1638</td>   <td>50.3167</td> <td>0.0000</td> <td>7.9198</td>  <td>8.5618</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>-0.0083</td>  <td>0.0015</td>   <td>-5.4073</td> <td>0.0000</td> <td>-0.0114</td> <td>-0.0053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>-0.1383</td>  <td>0.0292</td>   <td>-4.7272</td> <td>0.0000</td> <td>-0.1956</td> <td>-0.0809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>-0.0155</td>  <td>0.0033</td>   <td>-4.7576</td> <td>0.0000</td> <td>-0.0219</td> <td>-0.0091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>0.0321</td>   <td>0.0053</td>   <td>6.0469</td>  <td>0.0000</td> <td>0.0217</td>  <td>0.0425</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>0.0957</td>   <td>0.0064</td>   <td>14.8573</td> <td>0.0000</td> <td>0.0830</td>  <td>0.1083</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>-0.0000</td>  <td>0.0000</td>   <td>-2.0269</td> <td>0.0427</td> <td>-0.0000</td> <td>-0.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>0.0153</td>   <td>0.0013</td>   <td>11.5958</td> <td>0.0000</td> <td>0.0127</td>  <td>0.0179</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>-0.0122</td>  <td>0.0011</td>  <td>-11.5112</td> <td>0.0000</td> <td>-0.0143</td> <td>-0.0101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>-0.1160</td>  <td>0.0018</td>  <td>-64.9181</td> <td>0.0000</td> <td>-0.1195</td> <td>-0.1125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>-0.0000</td>  <td>0.0000</td>   <td>-1.5776</td> <td>0.1147</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: MNLogit\n",
       "==================================================================\n",
       "Model:               MNLogit          Pseudo R-squared: 0.130     \n",
       "Dependent Variable:  urate_bin        AIC:              61373.1393\n",
       "Date:                2021-03-02 14:28 BIC:              61558.6179\n",
       "No. Observations:    33889            Log-Likelihood:   -30665.   \n",
       "Df Model:            20               LL-Null:          -35259.   \n",
       "Df Residuals:        33867            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 0    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const  5.4318   0.1866  29.1109 0.0000  5.0661  5.7975\n",
       "       pct_d_rgdp -0.0059   0.0019  -3.1928 0.0014 -0.0096 -0.0023\n",
       "     pos_net_jobs -0.0826   0.0343  -2.4087 0.0160 -0.1499 -0.0154\n",
       "       emp_estabs  0.0190   0.0035   5.3569 0.0000  0.0121  0.0260\n",
       "estabs_entry_rate -0.0081   0.0065  -1.2467 0.2125 -0.0209  0.0047\n",
       " estabs_exit_rate  0.0319   0.0078   4.0665 0.0000  0.0165  0.0472\n",
       "              pop  0.0000   0.0000   2.0204 0.0433  0.0000  0.0000\n",
       "    pop_pct_black  0.0059   0.0015   3.8319 0.0001  0.0029  0.0089\n",
       "     pop_pct_hisp -0.0105   0.0013  -8.1890 0.0000 -0.0130 -0.0080\n",
       "             lfpr -0.0827   0.0020 -41.4428 0.0000 -0.0866 -0.0788\n",
       "          density  0.0000   0.0000   0.2440 0.8072 -0.0000  0.0000\n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 1    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const  8.2408   0.1638  50.3167 0.0000  7.9198  8.5618\n",
       "       pct_d_rgdp -0.0083   0.0015  -5.4073 0.0000 -0.0114 -0.0053\n",
       "     pos_net_jobs -0.1383   0.0292  -4.7272 0.0000 -0.1956 -0.0809\n",
       "       emp_estabs -0.0155   0.0033  -4.7576 0.0000 -0.0219 -0.0091\n",
       "estabs_entry_rate  0.0321   0.0053   6.0469 0.0000  0.0217  0.0425\n",
       " estabs_exit_rate  0.0957   0.0064  14.8573 0.0000  0.0830  0.1083\n",
       "              pop -0.0000   0.0000  -2.0269 0.0427 -0.0000 -0.0000\n",
       "    pop_pct_black  0.0153   0.0013  11.5958 0.0000  0.0127  0.0179\n",
       "     pop_pct_hisp -0.0122   0.0011 -11.5112 0.0000 -0.0143 -0.0101\n",
       "             lfpr -0.1160   0.0018 -64.9181 0.0000 -0.1195 -0.1125\n",
       "          density -0.0000   0.0000  -1.5776 0.1147 -0.0000  0.0000\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit = sm.MNLogit(y_train.cat.set_categories(new_categories = ['lower', 'similar', 'higher']),\n",
    "                                                    x_train).fit(maxiter = 150)\n",
    "fit_mnlogit.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n",
    "### MN Logit Marginal Effects\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>urate_bin</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>          <td>dydx</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>             <td>overall</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <th>urate_bin=lower</th>     <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>    0.0014</td> <td>    0.000</td> <td>    5.321</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>    0.0218</td> <td>    0.005</td> <td>    4.410</td> <td> 0.000</td> <td>    0.012</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0006</td> <td>    0.001</td> <td>    1.178</td> <td> 0.239</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>   -0.0033</td> <td>    0.001</td> <td>   -3.646</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0135</td> <td>    0.001</td> <td>  -12.259</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td> 6.069e-09</td> <td> 7.85e-09</td> <td>    0.773</td> <td> 0.439</td> <td>-9.31e-09</td> <td> 2.15e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0022</td> <td>    0.000</td> <td>   -9.417</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>    0.0021</td> <td>    0.000</td> <td>   12.016</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>    0.0192</td> <td>    0.000</td> <td>   82.527</td> <td> 0.000</td> <td>    0.019</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> 1.589e-06</td> <td> 1.42e-06</td> <td>    1.121</td> <td> 0.262</td> <td>-1.19e-06</td> <td> 4.37e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urate_bin=similar</th>    <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>   -0.0002</td> <td>    0.000</td> <td>   -0.729</td> <td> 0.466</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>   -0.0007</td> <td>    0.004</td> <td>   -0.154</td> <td> 0.878</td> <td>   -0.009</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0041</td> <td>    0.000</td> <td>    9.082</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>   -0.0039</td> <td>    0.001</td> <td>   -4.576</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0033</td> <td>    0.001</td> <td>   -3.272</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>  2.25e-08</td> <td>  6.3e-09</td> <td>    3.573</td> <td> 0.000</td> <td> 1.02e-08</td> <td> 3.48e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0004</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.016</td> <td>   -0.001</td> <td>-7.59e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>   -0.0005</td> <td>    0.000</td> <td>   -3.125</td> <td> 0.002</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>   -0.0025</td> <td>    0.000</td> <td>  -12.044</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> 1.491e-06</td> <td> 1.09e-06</td> <td>    1.362</td> <td> 0.173</td> <td>-6.55e-07</td> <td> 3.64e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urate_bin=higher</th>     <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>   -0.0012</td> <td>    0.000</td> <td>   -4.247</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>   -0.0211</td> <td>    0.005</td> <td>   -4.090</td> <td> 0.000</td> <td>   -0.031</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>   -0.0047</td> <td>    0.001</td> <td>   -8.287</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>    0.0072</td> <td>    0.001</td> <td>    7.606</td> <td> 0.000</td> <td>    0.005</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>    0.0167</td> <td>    0.001</td> <td>   14.981</td> <td> 0.000</td> <td>    0.015</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-2.857e-08</td> <td> 9.12e-09</td> <td>   -3.132</td> <td> 0.002</td> <td>-4.65e-08</td> <td>-1.07e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>    0.0026</td> <td>    0.000</td> <td>   12.893</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>   -0.0016</td> <td>    0.000</td> <td>   -8.332</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>   -0.0166</td> <td>    0.000</td> <td>  -68.660</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>-3.079e-06</td> <td> 1.64e-06</td> <td>   -1.877</td> <td> 0.060</td> <td>-6.29e-06</td> <td> 1.35e-07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "       MNLogit Marginal Effects      \n",
       "=====================================\n",
       "Dep. Variable:              urate_bin\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "=====================================================================================\n",
       "  urate_bin=lower      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp            0.0014      0.000      5.321      0.000       0.001       0.002\n",
       "pos_net_jobs          0.0218      0.005      4.410      0.000       0.012       0.032\n",
       "emp_estabs            0.0006      0.001      1.178      0.239      -0.000       0.002\n",
       "estabs_entry_rate    -0.0033      0.001     -3.646      0.000      -0.005      -0.002\n",
       "estabs_exit_rate     -0.0135      0.001    -12.259      0.000      -0.016      -0.011\n",
       "pop                6.069e-09   7.85e-09      0.773      0.439   -9.31e-09    2.15e-08\n",
       "pop_pct_black        -0.0022      0.000     -9.417      0.000      -0.003      -0.002\n",
       "pop_pct_hisp          0.0021      0.000     12.016      0.000       0.002       0.002\n",
       "lfpr                  0.0192      0.000     82.527      0.000       0.019       0.020\n",
       "density            1.589e-06   1.42e-06      1.121      0.262   -1.19e-06    4.37e-06\n",
       "-------------------------------------------------------------------------------------\n",
       "urate_bin=similar      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           -0.0002      0.000     -0.729      0.466      -0.001       0.000\n",
       "pos_net_jobs         -0.0007      0.004     -0.154      0.878      -0.009       0.008\n",
       "emp_estabs            0.0041      0.000      9.082      0.000       0.003       0.005\n",
       "estabs_entry_rate    -0.0039      0.001     -4.576      0.000      -0.006      -0.002\n",
       "estabs_exit_rate     -0.0033      0.001     -3.272      0.001      -0.005      -0.001\n",
       "pop                 2.25e-08    6.3e-09      3.573      0.000    1.02e-08    3.48e-08\n",
       "pop_pct_black        -0.0004      0.000     -2.406      0.016      -0.001   -7.59e-05\n",
       "pop_pct_hisp         -0.0005      0.000     -3.125      0.002      -0.001      -0.000\n",
       "lfpr                 -0.0025      0.000    -12.044      0.000      -0.003      -0.002\n",
       "density            1.491e-06   1.09e-06      1.362      0.173   -6.55e-07    3.64e-06\n",
       "-------------------------------------------------------------------------------------\n",
       " urate_bin=higher      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           -0.0012      0.000     -4.247      0.000      -0.002      -0.001\n",
       "pos_net_jobs         -0.0211      0.005     -4.090      0.000      -0.031      -0.011\n",
       "emp_estabs           -0.0047      0.001     -8.287      0.000      -0.006      -0.004\n",
       "estabs_entry_rate     0.0072      0.001      7.606      0.000       0.005       0.009\n",
       "estabs_exit_rate      0.0167      0.001     14.981      0.000       0.015       0.019\n",
       "pop               -2.857e-08   9.12e-09     -3.132      0.002   -4.65e-08   -1.07e-08\n",
       "pop_pct_black         0.0026      0.000     12.893      0.000       0.002       0.003\n",
       "pop_pct_hisp         -0.0016      0.000     -8.332      0.000      -0.002      -0.001\n",
       "lfpr                 -0.0166      0.000    -68.660      0.000      -0.017      -0.016\n",
       "density           -3.079e-06   1.64e-06     -1.877      0.060   -6.29e-06    1.35e-07\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************\n",
    "### MN Logit Regularization \n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'l1_ratio': 0.5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.arange(-5, -1, step = 1),\n",
    "    'l1_ratio':  np.arange(0, 1, step = 0.1)\n",
    "}\n",
    "\n",
    "lr_cv = lm.LogisticRegression(penalty = 'elasticnet', solver = 'saga',\n",
    "                              max_iter = 1e3, random_state = 490)\n",
    "grid_search = GridSearchCV(lr_cv, param_grid, \n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = 10)\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $C = \\frac{1}{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.9170222634572774\n",
      "            Iterations: 48\n",
      "            Function evaluations: 48\n",
      "            Gradient evaluations: 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-0.210202</td>\n",
       "      <td>-0.736071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_d_rgdp</th>\n",
       "      <td>0.053859</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_net_jobs</th>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_estabs</th>\n",
       "      <td>0.050222</td>\n",
       "      <td>0.140933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_entry_rate</th>\n",
       "      <td>-0.063547</td>\n",
       "      <td>-0.078584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_exit_rate</th>\n",
       "      <td>-0.228397</td>\n",
       "      <td>-0.143882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>0.014490</td>\n",
       "      <td>0.045453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_black</th>\n",
       "      <td>-0.184031</td>\n",
       "      <td>-0.109292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_hisp</th>\n",
       "      <td>0.138715</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfpr</th>\n",
       "      <td>1.256061</td>\n",
       "      <td>0.345394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1\n",
       "const             -0.210202 -0.736071\n",
       "pct_d_rgdp         0.053859  0.000000\n",
       "pos_net_jobs       0.045208  0.000658\n",
       "emp_estabs         0.050222  0.140933\n",
       "estabs_entry_rate -0.063547 -0.078584\n",
       "estabs_exit_rate  -0.228397 -0.143882\n",
       "pop                0.014490  0.045453\n",
       "pop_pct_black     -0.184031 -0.109292\n",
       "pop_pct_hisp       0.138715  0.000000\n",
       "lfpr               1.256061  0.345394\n",
       "density            0.000695  0.004797"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will get convergence warnings\n",
    "# They are due to difficulty converging\n",
    "# We can address this by accepting some error\n",
    "# with our qc_tol\n",
    "# See below\n",
    "fit_logit_reg = sm.MNLogit(y_train, x_train_std\n",
    "                          ).fit_regularized(alpha = 1/best['C'],\n",
    "                                            L1_wt = best['l1_ratio'],\n",
    "                                            qc_tol = 1e3)\n",
    "fit_logit_reg.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you can decide whether or not to keep variables if you wish to refit without regularization.\n",
    "As a rule of thumb, drop features that are 50% zero across classes.\n",
    "\n",
    "***\n",
    "## MN Logit Prediction Diagnostics\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We will proceed as we did for the binomial logistic regression.\n",
    "We will first fit the null model and then compare it to another model.\n",
    "\n",
    "********\n",
    "### MN Logit Null Model\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "higher     14820\n",
       "lower      12856\n",
       "similar     6213\n",
       "Name: urate_bin, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the largest grouping of counties have much higher than national unemployment rates.\n",
    "We will predict that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43416937149601653"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_mnlogit_null = np.mean(y_test == 'higher')\n",
    "acc_mnlogit_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "### MN Logit Full Model\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_mnlogit_sk = lm.LogisticRegression(solver = 'liblinear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEtCAYAAAAbeVcBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABEG0lEQVR4nO3deVxU9frA8c8MA7IpuCG44MIVXFAzTcP0moBck8xwxUwtl9TrlmVqP0uri6W55dLttril5IbmvuQuVmqLuQMVopJsKgiIwDBzfn8QUwTKwQaHgef9ek0x53zPmecMOM9816NRFEVBCCGEKIHW0gEIIYSwDpIwhBBCqCIJQwghhCqSMIQQQqgiCUMIIYQqOksHYA2ys7M5f/48tWvXxsbGxtLhCCH+JoPBQEpKCr6+vtjb25v13GlpaWRmZqou7+zsjKurq1ljKCuSMFQ4f/48gwcPtnQYQggzCw8Pp3379mY7X1paGkGBHbidoVF9jIuLC1999ZVVJA1JGCrUrl0bgLVLjLi7WTgYK9blyEBLh1AhNJ52ztIhWL08XS7JDWJN/7bNJTMzk9sZGj5fasBdxakTU2DohNtkZmZKwqgoCpqh3N2gnoeFg7FiimtVS4dQIejy7CwdQoVRVk3MtWsZcXcvuZxBAbCeZm5JGEIIYWZGFIyqylkXSRhCCGFmCgpGSl51SUF9X0d5IAlDCCHMzICCQcUyfYaHEIs5ScIQQggzM6qsYUiTlBBCVHJGFAySMIQQQpREahhCCCFUMSgq+zCs7G5EkjCEEMLMFNTVHqwsX0jCEEIIczOo7MOQUVJCCFHJGRR1zU3SJCWEEJWcNEkJIYRQxYBGVXOTQWZ6CyFE5ZanaNCrqD7kKZIwhBCiUpMahhBCCFWMigajihqGUWoYQghRuRlV1jCMUsMQQojKLb9JquRkIPMwhBCiklPfJFX2sZiTJAwhhDAz9U1S1kUShhBCmJlB0cpMbyGEECUzopV7egshhCiZNEkJIYRQxaBoMKiYY5F/zwzraZeShCGEEGZmRKNqjkV+DUMShhBCVFpGtKrmYRhVr2tbPkjCEEIIMzOgVdckZUW1C5CEIYQQZpffJKVVUc56ahcgCUMIIczOqLLTWxYfFEKISs6AFoOKGoasJSWEEJWcUdFiVFQ0SVlXF4aKFCiEEKJU8ifuaUt8POjy5gcOHKBt27YAGAwGZs+eTY8ePejevTvr1q0zlYuLi2Pw4MH07NmTfv368euvv5r2RURE0LNnT4KCgpg1axZ6vb7E15WEIYQQZlYwcU/No7Ti4uKYO3eu6fn69euJi4tj586dREREsHr1as6ePQvAlClTCA0NZffu3UyYMIFJkyahKAoxMTEsXbqUtWvXsnfvXjIyMli1alWJry0JQwghzCx/LSl1j9K4e/cur732GtOnTzdtO3DgAH369EGn0+Hi4kJwcDDbt28nKSmJ2NhYgoODAejatStZWVlcvHiRgwcP4u/vT40aNdBqtQwcOJDt27eX+PrSh2EFvtnjwvsTPdn68zn+M6oR1y9XMe1LvGZH68czeXv1ZdO2fetq8PUeF975PH+bosDn89w5vssVAO9Hspjw3jXsHa2sAfUBVf32JjX2JqJoQLHTkvycJzmNnHA5lIxL5A00eiM5DR1JeqERiq0Wh6h0am+MR2NQMNppSRnUgOwmzoXO6bo/CZdjKVz5j6+Frqq8UZjywTXiouyJ+J8bWq3CS7Ou075bBjY2ChH/q82uNbUsHeRDk6fYoFdsVJTL/39iYmKRfdWqVaNatWqFts2cOZOBAwfi4+Nj2paQkICHh4fpubu7O9HR0SQkJODm5oZW+0dSqlOnDomJiSQkJFC/fv1CxyQlJZUYr8VrGCdPnuTpp58usn3x4sVs3br1vsdu2bKF0aNHl1Fk5cNvsXZ88p+6KL//Yb35aRwfHYjmowPRvDz/Ks7VDIx7Nx6A9FQbFk+rz0cz6xWaDvT1Hhe+P1KV/+6P5pMjUeTc1bJ1ee2HfzEWYJuYTe1N8cRPbsrVt1py62kP6n74K84/pOJ6KJn4V7258k5LNLlGXPcnQZ4Rj//FkjSsEVfezi/v/tnlQue0/zmDGnuK/gOvrBr8I5u5G2Pp8vRt07aeQ25Sr0kOL3XzYULPpoSMuoHPI1kWjPLhym9u0qp45DdJDR48mICAgEKP1atXFzpneHg4Op2Ofv36FdquKAoajabQc61Wi9FoLLS9YJ+NjQ2KohTZ/ufEci/ltoYxadIkS4dgcdlZGuZOaMjoWb8xZ1zDQvv0uRrmT2rImHd+w61efmfVsR2u1KyjZ9TM65zY/8c3k849b/N499vobOFOhpa0GzqqVbe2AX0PRtFpSBrWEIOrHQDZjZzQ3dbjEplCalAdjM75/wSShzZEk6eATkvs/Nag04KiYJuSg8H5j38mNrf1uIVfJWVAfWrsSrDINZU3z7x4g73rapD8m61p2xNP3Wb32poYDRoyb+s4ss0V/76pRP/kaMFIHx6jymG1BU1S4eHhuLu7F9r319rFl19+SXZ2Nr1790av15t+rlOnDsnJyaZyycnJuLu7U7duXVJSUgollIJ9Hh4exR5TknKRMLKyspg8eTKxsbHk5OQQFhZGREQETZs2ZcSIERw9epT58+ej1Wpp3rw533zzDV988QUAKSkpvPTSSyQkJGBjY8OCBQvw8vIiIyOD2bNnExMTg16vx8/Pj6lTp6LT6fD19SUgIICoqCjmz59Pq1atLPwOFG/JtAYEP3+Txi2yi+zbu64GNeroeeKpP77VPT30JgBfbahRpLzOFratqMXq9z2o6Z5Lp6fSyizu8iSvVhXyav3ehKco1N5wjcxHXLG7fhddRh71FsWgS9Nzt6kzKf1/r6LrtNjc1tPwnYtoM/NIGN0kf7tRweOTWG70r49iY10TrsrShzPy37dH/5lh2la7rp6U638kkBsJtjRuXvTvuKLKv0Wr+ol77u7uhZqIihMREWH6OT4+nl69erFt2zbWrFnD5s2b6datG1lZWezatYu3334bd3d3PD092b17N8HBwURGRqLVavH29gbg3//+N2PHjqVGjRps2LCBwMDAEuO1eJMU5LffvfDCC2zbto3Q0FCWLl1q2peamsrUqVOZN28e27Zto2PHjoXa2q5du8aMGTPYsWMH7du3Z/ny5QC8++67tGzZki1btrB161ZSU1NZuXIlAHq9nm7durFv375ymyx2rKqJ1kbhX4NuFbv/y09r89zLJbc5/lnv4TfYfOkcTzx1m7BRjc0RptXQ5Bjw+CgW2+Qckl5oiMag4HghnYQxXlx5sznaOwZqbfnNVN7gYkvsgjZc+79muK+MwzYxm1qb48nyrkpWSxcLXol10GgU/tzqoQGMlaNSC6BqSK3ayX0lGTRoEA0aNKB3797069ePfv360aFDBwAWLlzI+vXrefrpp1m0aBGLFy9Gq9XSrFkzxo0bx7Bhw+jRowc2NjaMGjWqxNcqFzWMBg0a0KZNGwCaNWvG5s2bTZ0433//PV5eXjRr1gyAkJAQwsLCTMe2bt2ahg3zm2uaN2/O/v37AThy5Ajnzp0zZeXs7MLfbtq3b1+2F/U3fbWxBjl3tYwN9CFPryE3O//nsLW/kppiiyFPQ2u/TFXn+vWCPYpRwz9a3UWjgR7P3WLrZ5WjDwNAdzOHekt+IcfDnvjXfFDstOS52pLZzhWjQ37HZMbjNaixIwFtVh6OURlkPlodgJyGTuQ0cKBK/F2qfXsLQ1UdzqdT0eYY0aXm4vnWBa6+1dKSl1cupVy3o2adPNPzGu56biTY3ueIikX9xL0HSxj169fn9OnTAOh0OmbMmFFsuUaNGrFmzZpi9/Xt25e+ffuW6nXLRcKwtf3jD0mj0RTqkCmug+bPnTM6na7YY41GI4sXL8bLywuA9PT0Qh1Ajo7luy116e6fTT8nXrNjdDcfPjoQDcDRHdV55IlMNCpbRS5fcmDz/9xYtD0Ge0eFA5uq0+YJdcnG2mnuGqj/fjTpnWpxq3dd0/bM9tVx/i6V211qo9hqcD6dRk5jRxSthjor48irqiO7aVXsfruLXUI22U2ciF3YxnS8Q1Q6buFXJVncwzf7qvGvQbc4sb8aDk5GnuydxpJp929yqUiMoHJ5c+tSLhLG/Tz66KPExcURFRVFs2bN2LdvX5EP/+J07tyZVatW8c4776DX6xk7diydO3dm7NixDynysnM91o46DXJVlw/sl8r1y1WY8JQPNjqFht7ZvLLgahlGWH64HkrG9mYuzqdTcT6datoeP8UHbaYBz3cuojEqZDd0ImVgQxR7G66P/wdu66+BQUHRaUl4qQl5NewseBXWZ+fqWtRtmMv/DkSjs1XYvbYm5044l3xgBWFEZQ2jfPQKqFbuE4arqysLFy5k2rRpaLVafH190el0ODg43Pe4GTNmMHv2bHr16oVer6dTp06MHDnyIUVtXu4Nctn2yznT8/Hv/Xaf0hA08BZBAwv3fQx9LZGhr1W+oaCpwR6kBnsUu+9W77qFah0F7vpU5eqbLe573rvNqskcjL9YMNnT9LPRoOF/s+pZMBrLMqBRVcNQU6Y8sXjC6NixIzt37rzn88zMTCIjI1m/fj0ODg5cuHCBw4cPU716dfr06UOfPn1MZf/8vEaNGixYsKDY14yOji6jqxFCCFBU9mEoD9iHYSkWTxglcXZ2xtbWln79+qHT6dDpdHzwwQclNkkJIYSlFEzMU1POmpT7hAEwefJkJk+ebOkwhBBCFSOoWolWOr2FEKKSM6qsYTzosFpLkYQhhBBmVtqZ3tZCEoYQQpiZ+lu0Sg1DCCEqNUVlDUORGoYQQlRuRjSqJuU96C1aLUUShhBCmJna268+yC1aLUkShhBCmJl0egshhFBFUbmWlCKd3kIIUbnJWlJCCCFUkSYpIYQQqhgULXmKjapy1kQShhBCmJmMkhJCCKFKWd+i1VIkYQghhJnJTG8hhBCq5M/0VrO8uSQMIYSo1GSUlBBCCFXyE4aaPgxJGEIIUakpqOzDkCYpIYSo3KQPQwghhCrShyGEEEIVSRhCCCFUkXkYQgghVJEahhBCCFWMqOvQNpZ9KGYlCUMIIcxMahhCCCFUkT4MIYQQqkgNQwghhCpGlTO9ZeKeEEJUcoqiUdXcJE1SQghRySkqlwaRtaSEEKKSMyoaNNKHIYQQoiQGowaMJS9vbjBKwhBCiEqt0vVhhISEPNAJNRoNW7ZseeCAyrPuq59H41TN0mFYrZ/GLbB0CBXCAPwsHYIoQaWbh3Hp0qUHOqFGY11vgBBCmJui5D/UlLMm90wYUVFRDzMOIYSoMPJHSMk8DCGEECVQUNmHUdETxrFjx9iyZQuXLl0iPT2db7/9lu3bt3P16lVGjBiBg4NDWcQphBBWw6hooAyG1a5du5Z169ah0Who0KABYWFhuLq6MmfOHCIjIzEYDAwfPpxBgwYBEBcXx4wZM0hNTcXR0ZG5c+fi5eUFQEREBCtWrCAvLw8/Pz/eeOMNbG1t7/v6JY/7+pOZM2cyevRo9u7dS3x8PGlpaQCcP3+eZcuW8cILL3Dnzp1SvQFCCFHRFPRhqHmodf78eVasWMH69evZuXMnjRo1YvHixaxfv564uDh27txJREQEq1ev5uzZswBMmTKF0NBQdu/ezYQJE5g0aRKKohATE8PSpUtZu3Yte/fuJSMjg1WrVpUYg+qEsX79ejZu3EhQUBBfffUVY8aMMe0bN24cffv25cyZM6xcuVL9OyCEEBXR78NqS3qoqYUU8PX1Zd++fVStWpWcnBySkpJwdXXlwIED9OnTB51Oh4uLC8HBwWzfvp2kpCRiY2MJDg4GoGvXrmRlZXHx4kUOHjyIv78/NWrUQKvVMnDgQLZv315iDKVKGD4+PixevBhPT89Co6FcXFyYPXs2rVq1Ys+eParfACGEqIjyaw9qkkZ++cTEROLj4ws90tPTi5zX1taWAwcO8M9//pPvvvuOPn36kJCQgIeHh6mMu7s7iYmJJCQk4Obmhlb7x8d8nTp1TPv+ekxSUlKJ16W6D+Py5csMGTLkvmU6dOhAeHi42lMKIUSFpHZpkIKO8cGDBxfZN378eCZMmFBke2BgIIGBgWzcuJERI0ag0+kKfYFXFAWtVovRaCwyzUFRFGxsbFD+0hZWcExJVCcMe3t7bt68ed8yycnJ2Nvbqz2lEEJUSIoClGIeRnh4OO7u7oX2VatWeJLwlStXSElJoX379gD07duXWbNm0b59e5KTk03lkpOTcXd3p27duqSkpKAoiilxFOzz8PAo9piSqG6SateuHfv37ychIaHY/XFxcRw4cIBHH31U7SmFEKJCUtcc9cfQW3d3d+rXr1/o8deEkZKSwiuvvMKtW7cA2LFjB02bNiUoKIjNmzeTl5dHeno6u3btIjAwEHd3dzw9Pdm9ezcAkZGRaLVavL298ff359ChQ9y8eRNFUdiwYQOBgYElXpfqGsa4ceM4fvw4/fv3Z8SIEVy+fBmAU6dOce7cOT799FP0ej2jR49We0ohhKiQFNR1aJdmHkb79u0ZM2YMQ4cOxcbGBjc3Nz788EM8PDy4evUqvXv3Rq/XM3DgQDp06ADAwoULefPNN/noo4+ws7Nj8eLFaLVamjVrxrhx4xg2bBh6vZ42bdowatSoEmPQKH9tzLqPo0ePMn36dFJTU/84gUaDoig4OzsTFhZGjx49VL8B1iI+Pp6AgAA0Tz0na0n9Dd/IWlJmMaC+rCX1d+XpcrneOIqDBw9Sv359s5234LOCqb2hunPJB6RmwvvbzB5HWSnVxL2uXbty+PBhDh48yIULF8jIyMDR0REfHx+6d+9O1apVyypOIYSwGqqHzCoaq5rrXeqZ3vb29gQHB5vG9gohhPgLlZ3eqsqUI6VOGAUzCqOjo8nKysLFxQVfX1+Cg4OpU6dOWcQohBBWRWoY5HegLF++HIPBUGj77t27Wbx4MTNmzGDAgAFmDVAIIayN2mG1FbaGsWHDBj755BOaNm3K2LFjadWqFU5OTiQnJ3P69Gk+/fRTZs2aRe3atenWrVtZxiyEEOVaaWoY1kR1wggPD6du3bqsXbsWFxcX0/YaNWrQrFkzAgIC6NOnDx999JEkDCFE5VZBE4bqiXtxcXH4+/sXShZ/5ubmRvfu3YmOjjZbcEIIYY3KYrXa8kB1DcPDw6PYxbD+TK/XU7Nmzb8dlBBCWDNFAYxqahhlHopZqa5hvPjii+zevZsjR44Uu/+nn35i586dPP/88+aKTQghrJNSiocVuWcN47333iuyzdXVlbFjx9KxY0fatm1LrVq1SE9P59y5cxw7dox69eqh08ldX4UQlVul6/RevXr1PQ86ceIEJ06cKLL9ypUrvPfeewwdOtQ80QkhhDWqbMNqP//884cZhxBCVCCa3x9qylmPeyaMgtUOhRBClFJlq2HcS05ODmlpaRiNRtNdmxRFIS8vj7S0NI4ePcrEiRPNHqgQQliNyp4w7t69y/Tp0zl48GCRpUH+ShKGEKJSq6Cd3qqH1S5btox9+/bh6upKly5dqFKlCk2aNKFz587UrVsXRVGoWbMmH374YVnGK4QQVqGiTdqDUtQwDhw4gLu7O7t378bR0ZExY8Zga2vL0qVLAfjwww9ZtmwZOTk5ZRasEEJYhQraJKW6hpGQkIC/vz+Ojo4AtGzZktOnT5v2jxs3jubNm7Nu3TrzRymEENakoElKzcOKqE4YOp0OJycn03NPT09u3rzJzZs3Tds6duxIXFycWQMUQgiro4BGxaPC1jA8PT0LLSzYuHFjFEUhKirKtE2v15ORkWHeCIUQwtpU0KVBVCeM7t27c/z4cZYsWcLt27dp1qwZLi4ufPrpp2RlZXHt2jX27t1rFTcyF0KIMlXZm6RefPFFfH19+eijjzhw4AB2dna88MILnDhxgg4dOhAUFMSNGzcIDQ0ty3iFEKL8q6A1DNWjpBwdHVm3bh379u2jRYsWAKaRUrt27aJKlSr06tWLwYMHl1mwQghhFSroKKlSzfS2sbGhZ8+epucajYaRI0cycuRIswcmhBBWzcqSgRqyFnm5p/Bu4CFibtZk1elHcKmSzZvdjtGs1g3u6m358lIzvjjbCgBft2Smd/kaB1s9Wo3C8h/bsjPau9DZhrQ5Q9+Wl3j2i8rVdHhqb3WWTWrK59GnABjRqj01PHJN+58Zc50ufW5w/utqrPlPQwx5GqpWz2PY23E0apGFosCG+Q04ubsGAF5tMhn13mWqOBgtcj3llX+fVPqPTUYBcu5q+e8b9fj5rKOlw3r4KuhMb7MvPqjRaDh58uQDBwRw8uRJ/vOf/7Bz586/dR5r16R6Km90PUYr92RibubfyXBal6/JyrXlmfBQbDQKS4L38lt6VY7GNeSDnvt442A3TlyrTx2nTDaFbuJsohtXb7sC0NYjgeGP/sTtnCoWvKqHLyHWnjX/aWSaWXv9V3ucXfOY99XZQuWy0m1Y8JIPr3wcTavO6fz2iz3vD2/G/P1n+PFgdc4ccWXevrPY2CosGuPN7uXuhIy/boErKp/qe2Uz8s3rjP+XN7eSbXnMP52Zy+MY8lgLS4f20KkeMmtltZB7JgxnZ+eHGYcoxqDW59l8sTkJmVVN21q4pTD7aBeMihajAsfiGhL0j1i+vVaf/55qz4lr+aPUku44k3rXAXfnO1y97UpNhyxmdD3O/K/9GNX+R0td0kOXc1fL0on/YNisOBaPbwpA9PdV0doozOzTkqx0Gx4PvkWfifEkXLbHsWoerTrn34q43j+ycaxqIOaHqnTseYt23VPR2SpkZdhw+4YtVV3zLHlp5Y4+R8sHUxpwK9kWgJgzDlSvnYfO1kieXvX4moqhsiWMQ4cOPcw4ipWRkcHbb79NVFQUGo2GLl268MorrzB37lycnJx4+eWXSU5OpkuXLqxevZrHH3+cbdu2cfjwYT744AM2bdrEunXrMBqNuLq68uabb+Ll5cX06dNJS0vj2rVrPPnkk7z22muWvtRizT7aBYBOnvGmbWcT69DLJ4bTCe7Y2Rjp7vUreUYbcg06tlxsbirXv+VFnOz0nEmsg1Zj5P1/HWDB14+TZ6xc/3A/mdaEwOeT8GyeZdpmyNPQqvNtnvu/qxj0GuYMa4ZD1Ty6DUwhO8uGM0ddaNP1Nr/85MS1aAdSf/8A1Nkq7F3pzvp5DajhnkuHp25Z6rLKpaR4O5Li7X5/pjD6reuc+Kpa5UsWFVi5/k2GhYXh6urKjh072Lx5M9HR0axYsYKgoCCOHTsGQGRkJLVr1+abb74B8hNdUFAQp06dYuvWrYSHh7N161ZGjhzJ+PHjTefOzs5m165d5TZZ3Mu8451QgIjQTSwJ3sM31xqg/0sSGNnuR8Z1/I5xO58ix6Bjst9Jvr/uwbfXGlgmaAvZt7oONjoF/9CUQtsDByczPCwOe0cjTi4GgkclcGpPTRyrGnhteTRfLq3Ha91bcyyiNr5PpKOz/eNrYI8XE1l54Ts69LjFgpd8HvYlWYUqDgZmfHyFuo1yWTSlcv3NFdAYNaof1qRcd3ofO3aMdevWodFosLOzIzQ0lNWrVzNy5EiSkpK4ceMGkZGRjB07li1btjB+/Hi+++473n33XT788EOuXLlSaF5Ieno6aWlpALRr185CV/X3ONvlsvBrP27n2AMwqv0PXE1zAcBWa+Dd7ofwqpHKc5tCuJ5RDYBezWK4ddeBwCaXcbTV4+Z8h82hG+m7foDFruNhOLLRjdxsLa8FtSZPrzH9HDwqgcYt79Cwxe+1DgV0tkaMRrB3MvBWxEXTOSZ1eQT3xtnEXXREMUJj3yw0GvAflMzu5R4WurLyq3a9XN5ZdZmrv9gztb8Xudnl+jtp2alsTVLlgdFoRKPRFHqel5eHVqvlySef5OjRo5w9e5b333+fjz/+mL1799K2bVucnJwwGo307t3bVIMwGo0kJyfj4pL/4VqwiKK1GdDqAs52emYf7UJNhyz6trjElL1BAMwNOoC9bR6DN4VwN8/WdMyTK4aZfn6s3m/M6BpZ4ZMFwHu7zpl+Tr5WhVcD2jDvq7Osne3Jqb01mPJJNHm5WvaucqdzyA00GnhvSHOmrojCq80dvtleE9sqRho2zyJycy12fFKXsG3nqeJg/L32cduCV1f+ODgZmBfxK/s3VSd8obulw7EsSRgPX+fOnVm7di3/93//h16vZ+PGjXTq1AmAoKAg5syZg7e3N3Z2djz++OMsXLiQyZMnm4594403GDZsGG5ubqxbt47PP/+cvXv3WvKS/rZPv3+UOUEH2frcejTAspMdOJ/sRhv3RP7VNJbLqS6s7felqfzCbx7n66uelgu4HOr/SjzL32jMq4FtMOg1PP70TQKeS0ajgUnLfubjqV7k6TVUd8vlteXRaDTwz343SIyzZ3rPVtjYKNT3ucuY+b9a+lLKlWdevIFb/VyeeOo2Tzz1RzKdNsCLjNRy/VFjdhqwumSgRrn+Lb7xxhuEhYXRq1cv9Ho9Xbp0YcyYMQD4+fmRnJzMoEGDgPwEsXv3bvz9/U3PR40axfDhw9FoNDg7O7Ns2bJCNRZrMeOAv+nnLL0dE3c9VaTMmUR3Wi4dW+K5vvutXqWbgwHg1iCHNTH5czCqOBj594LiP+xb+KXz/r6zxe4bMCWeAVPii90nYMOyOmxYVsfSYZQPUsN4eDp27Giag7FgwYJiy9jZ2fHDDz+Ynj/zzDM888wzhcoMHjy42KVK5syZY8ZohRDiLyRh5MvLy+Prr78mKiqKtLQ0pk2bRnR0NI6OjjRoUDlHRAghxJ9V1Il7pRrCcPLkSQIDAxkzZgyLFi1i1apVAOzZs4cePXqwfPnysohRCCGsi4LK5c0tHWjpqE4Yly5d4qWXXuLu3buMHj2aoKAg0742bdpQq1Yt5s+fXy4m/AkhhEVV0OXNVSeMJUuWUKVKFbZs2cLLL7+Mt/cfi9p169aNTZs24eLiwsqVK8skUCGEsBZqbs9quk2rFVGdMH744Qd69OhBvXr1it3v5ubGU089xc8//2y24IQQwipV0BqG6k7vnJycEie72djYkJOT87eDEkIIa1bp52F4eXnx9ddfYzQa0WqLVkz0ej3Hjx+ncePGZg1QCCGsTmUfJdW/f39+/vlnpk+fTmpqaqF9N2/eZMqUKVy5coU+ffqYPUghhLAqlb1JatCgQZw+fZrt27ezY8cOqlTJvwmPv78/iYmJGI1GAgMD5Z7eQohKr6LOwyjVxL3333+fbt26ERERwcWLF8nLyyMzM5N27doREhIitQshhChD27ZtY/ny5Wg0GhwcHJgxYwYtWrRgzpw5REZGYjAYGD58uGnJpLi4OGbMmEFqaiqOjo7MnTsXLy8vACIiIlixYgV5eXn4+fnxxhtvYGtre7+XL/1M76eeeoqnniq6lpEQQojflUENIzY2lnnz5rFlyxbc3Nw4evQoEyZMYNSoUcTFxbFz507u3LnDwIEDadmyJa1bt2bKlCkMGzaMXr16cfToUSZNmsSOHTv4+eefWbp0KV9++SWurq5MmTKFVatWMWrUqPvGUEkXqxdCiDKkdg5GKRKGnZ0dYWFhuLm5AeDr68uNGzfYu3cvffr0QafT4eLiQnBwMNu3bycpKYnY2FiCg4MB6Nq1K1lZWVy8eJGDBw/i7+9PjRo10Gq1DBw4kO3bt5cYg+oaRkhIiKpyGo2GLVu2qD2tEEJUPKWsYSQmJhbZVa1aNapVq2Z6Xr9+ferXr59/mKLw3nvv4e/vT0xMDB4ef9zMy93dnejoaBISEnBzcys0qrVOnTokJiaSkJBgOlfBMUlJSSWGqzphXLp0qcQydevWLXSBQghRKZUyYRQ3WGj8+PFMmDChyPasrCymT59OYmIin332Gf379y902wZFUdBqtUVuQFewz8bGBkVRimwvbrrEX6lOGFFRUcVuz87O5urVq3z00UecOXOGjz/+WO0phRCiQtKgftkPBQgPD8fdvfBdCov78n39+nXGjBmDl5cXn3/+Ofb29nh4eJCcnGwqk5ycjLu7O3Xr1iUlJQVFUUyJo2DfvY4pyd/uw7C3t8fb25uFCxdSrVo15s2b93dPKYQQ1q2U8zDc3d1NTU4Fj78mjMzMTIYMGUJQUBCLFi3C3t4egICAADZv3kxeXh7p6ens2rWLwMBA3N3d8fT0ZPfu3QBERkai1Wrx9vbG39+fQ4cOcfPmTRRFYcOGDQQGBpZ4WWa7gZJGo+GJJ54gIiLCXKcUQgirpDHmP0pkVN/vHR4ezvXr19m/fz/79+83bV++fDlXr16ld+/e6PV6Bg4cSIcOHQBYuHAhb775Jh999BF2dnYsXrwYrVZLs2bNGDduHMOGDUOv19OmTZsSR0iBme+4d+3aNXJzc815SiGEsD5lMKx29OjRjB49uth9M2bMKHZ7o0aNWLNmTbH7+vbtS9++fdUHgBn6MADu3LnDkSNHOHDgAH5+fqUKQAghKhrVS5dX1Jnezz77bJEe9z9TFAUHBwdeeeUVswQmhBBWq7IvDXK/hGFra0uTJk3o1asXNWvWNFtwQghhlSp7whg4cCAtWrQwLToohBCieKUZVmtNVA+rnThxIpMmTSrLWIQQomKo7Mubp6en849//KMsYxFCiAqhonZ6q65hBAQEsH//fm7dulWW8QghhPWr7DWMxx57jFOnThEQEEC7du2oV6+eaabhn2k0GqZPn27WIIUQwqpU9k7vt99+2/Tz8ePH71lOEoYQorLT/P6oaFQnjM8//7ws4xBCiIqjstUwAgICGDZsGEOHDgUwrU0ihBCiBCo7vZWKkjB+++030tPTH2YsQghRMVS2GoYQQoi/wcqSgRqSMIQQwszUzsOwttng900YGRkZXL9+vdQnrVu37gMHJIQQVq8yNkl9/vnnpR4dpdFouHjx4t8KSgghrFmlrGF4eHhQr169hxVLuWd3G7S5VvYbLke6z5Cl782hOt9aOgRRkspYw+jTpw/jx49/WLEIIUSFUClrGEIIIR5AZaxhCCGEKD2NAhqjunLWRBKGEEKYW2WrYYwfP56OHTs+zFiEEKJCyO/DKDkbVJgahnR2CyHEA6psNQwhhBAPRkZJCSGEUEdqGEIIIdSQGoYQQgh1pIYhhBBCLWurPaghCUMIIcxNahhCCCHUkD4MIYQQ6iiKuht2W9lNvSVhCCGEmUkNQwghhDrShyGEEEINjVHlarUqypQnkjCEEKIsWFntQQ1JGEIIYWbShyGEEEIdGSUlhBBCDalhCCGEUEdGSQkhhFBDahhCCCHUkT4MIYQQamgUlfMwrCtfSMIQQgizU9kkZW19GFpLByCEEBWOUVH/KCVFUZg2bRrLly8HwGAwMHv2bHr06EH37t1Zt26dqWxcXByDBw+mZ8+e9OvXj19//dW0LyIigp49exIUFMSsWbPQ6/UlvrYkDCGEMDelFI9S+PXXXxk2bBj79u0zbVu/fj1xcXHs3LmTiIgIVq9ezdmzZwGYMmUKoaGh7N69mwkTJjBp0iQURSEmJoalS5eydu1a9u7dS0ZGBqtWrSrx9SVhCCGEmRWMklLzAEhMTCQ+Pr7QIz09vch5w8PD6d+/Pz169DBtO3DgAH369EGn0+Hi4kJwcDDbt28nKSmJ2NhYgoODAejatStZWVlcvHiRgwcP4u/vT40aNdBqtQwcOJDt27eXeF3ShyGEEOZWylFSgwcPLrJr/PjxTJgwodC2mTNnAvD111+btiUkJODh4WF67u7uTnR0NAkJCbi5uaHV/lEvqFOnDomJiSQkJFC/fv1CxyQlJZUYriQMIYQws9LOwwgPD8fd3b3QvmrVqql6LUVR0Gg0hZ5rtVqMRmOh7QX7bGxsUP6SzAqOKYkkDCGEKAul6J9wd3cv9I2/NDw8PEhOTjY9T05Oxt3dnbp165KSklIooRTsu9cxJZE+DCGEMDONoqh+/F0BAQFs3ryZvLw80tPT2bVrF4GBgbi7u+Pp6cnu3bsBiIyMRKvV4u3tjb+/P4cOHeLmzZsoisKGDRsIDAws8bWkhiGEEOZm/P2hptzfNGjQIK5evUrv3r3R6/UMHDiQDh06ALBw4ULefPNNPvroI+zs7Fi8eDFarZZmzZoxbtw4hg0bhl6vp02bNowaNarE15KEIYQQZqa29vCgNYw5c+aYftbpdMyYMaPYco0aNWLNmjXF7uvbty99+/Yt1etKwhBCCHOT1WqFZSi83fswvyTXYM23jwDQv/15nm0bhb0uj0sJtXl7x5PoDTamI3o/EkW3Zpd5ef1TpnP8u9t3BLX4hbt6W85cq8PCrzqRa6hMv36FWf0P80tiDcIjHym0Z+7gfaRkODJ/e5dC2+tWT2f1+M1MXBHMpd/cAAjpcJGBnc5hMGq4nlqNsM1duZ3l8LAuotzz75NK/7HJKEDOXS3/faMeP591tHRYD5+CymG1ZR6JWZW7Tu9z584xceLEUh2zePFitm7dCoCPjw+3bt0qg8gevsa1Uvl4yA4Cm8eatvk3iyX0sfOMXfM0/T4aSBXbPAY/nj+rs5p9Nv/X8xhT/vU1mj/9JT7TJpouTa/w/Gd9GfRJf25kOvFv/+8e+vVYSqPaqfx35A78fWOL7Bvyz9M80iihyHY7XR5vDziIrY3BtK1u9XTGBp1i9Ce9GbxkAAmpzrwU+H2Zxm5N6ntlM/LN68wY3IR/d/fhiw/qMHN5nKXDsojSTtyzFuUuYbRq1YolS5aU6phJkybx7LPPlk1AFjSg/Xm+PN2c/RebmLYFt45hzYk2pGfbo6Bh9q5/sutsUwC6t/yVlExHPtjvV+g8zT1SOBLdiMycKgAcimpMYPNfqSz6+Z1n23fNOXiuSaHtjzb+DT/va2w51aLIMVOfOc7OH31Iy7I3bdNqFXQ2RhztctFoFOxt88jNsylybGWlz9HywZQG3Eq2BSDmjAPVa+ehszVDz67VUf6YvHe/h5VVMSzaJnHnzh1ef/11rly5glarpWXLlgQHBzN79mx27tzJ9OnTsbe3JyYmhps3b+Lv74+rqyuHDx8mJSWFsLAw/Pz8mD59Ok2bNmXEiBGmc2dlZfHWW29x5coV0tLScHJyYv78+TRp0oQhQ4bg4uJCbGwsgwYNYsiQIRZ8F+5t7t78JpLHm1wzbWtY8zYXrt9l2XO7qF31DqevevDBgccB2PxDSwB6tYkqdJ7zv9XhucfPsuGUL7fv2vN06xhqOWc9pKuwvIKmpo5N/3gfa1W9w6u9vmHiyp706XCxUPne7S+hszGy7bsWvNjtR9P2+JsurD3Whk2vrifjbhXu5Ngx4qOQh3MRViAp3o6keLvfnymMfus6J76qRp6+3H0vLXMaI/xlztw9y1kTi/4m9+/fz507d9i2bRsREREAxMfHFypz8eJFVq9ezdq1a1mxYgWOjo6sX7+eoUOH8umnn97z3MeOHaNatWps2LCBffv24evrS3h4uGl/tWrV2L17d7lNFvei0xro2CSeaRHdGfxpX6o55DC+26n7HrPrnDcHLjbh46E7WDl8K3E3XAv1eVQ2NloDYaEHWLSzEzcznArt86mbQp+OF3lva5cix3Vseo1uvrH0mjOEnu8N5ejFRszsd/hhhW01qjgYmPHxFeo2ymXRlAaWDscy1NQu1C4fUo5YtIbRrl07Fi1axJAhQ+jUqRPDhg0r0v/QrVs3bG1tqV27No6OjnTpkv8P2dPTk7S0tHueu0ePHjRo0IA1a9Zw5coVTp06Rdu2bU3727dvXybXVNZSMp04dKkxd3Lzv8ntPteUUf/84b7HVLPPZu/5pqz8+lEAWtdP5NotdcsOVEQt6qdQr0Y6Lwd/A0DNqlloNQpVdAaycm1xss9l+ZitANSumsU7Aw+yZI8fHZte49ilRqTeye/kjvi2Jete3mipyyiXatfL5Z1Vl7n6iz1T+3uRm135aheAjJIqCw0aNGD//v2cPHmSEydO8OKLL/LOO+8UKmNnZ1fouU6nLuQvvviCjRs3MnjwYHr16oWrq2uh2oujo3WO3DhwsQlBLX9l6+nm5OTZ8KTPZS7+Vvu+x7Som8KEgJMMWx6Comh48YnT7Dnf9CFFXP6cu+pOr7l/1CxHBXyHi1O2qelq0c4nTPu2Tl3LzA0BXPrNDVfHbPo9foG1xx7hbq4t3Xwvc/5anYcef3nl4GRgXsSv7N9UnfCFJS8zUZGV9TwMS7Fowvjiiy/44YcfmD9/Pl26dOHmzZtcvHix5ANVOH78OCEhIfTv35/09HTefvttvLy8zHJuS9r0fUtcHHIIH7UZrcZIVGJtZn/V6b7HnIhtQLuG19kwehMajcKR6MaEn2j9kCKuOHb84INH9Qw+Hx9Bbp4NiWlVeWdTN0uHVW488+IN3Orn8sRTt3niqdum7dMGeJGRWpmGcCP39C4Lzz77LKdOnaJnz544ODjg4eGBj48Pe/fu/dvnHj58ODNnzjT1jTzyyCPExMT87fNawlvb/U0/GxUtnxxrzyfH7t2ktuNMM3acaVZo24eHO/Lh4Y5lFqM1eCfCv9jtnx587J7HPPv+8396puGTA4/xyYF7l6/MNiyrw4ZlUuMC8pua1HRoW1e+QKP8dZ1bUUR8fDwBAQFU6fQcWoeqlg7HaunuWjqCiqH66m8tHYLVy9Plcr1xFAcPHnzgVWKLU/BZUc+pF7Za5xLL642Z/HZnh9njKCuVrJ4ohBAPgTRJCSGEUEXt/Aorm4chCUMIIcwsf9kPNaOkHkIwZiQJQwghzE2apIQQQqijdha3JAwhhKjc1C4sKDUMIYSo5IyAisUHrayCIQlDCCHMTaMohe5Jc79y1kQShhBCmJs0SQkhhFBF9dLlkjCEEKJyU303PUVdX0c5IQlDCCHMTTH9p2SSMIQQohIrTQ3DikjCEEIIczOWImFY0d2SJWEIIYS5KUbUrSxoXasPSsIQQghzkyYpIYQQqqgdVmtly9VKwhBCCHOTeRhCCCFUUbC6WdxqSMIQQghzkxqGEEIIVYzG30dKlUAjo6SEEKJyU4z5SaMkWkkYQghRuRmV3yfvlUSapIQQolJTFAVFRZOUYmUd45IwhBDC3KSGIYQQQhW1o6SkhiGEEJWc2k5vGSUlhBCVnNQwhBBCqKEYjSgqahiK1DCEEKKSU7s0iHVVMCRhCCGE2akdJSWr1QohRCWnqFwaRE2ZckQShhBCmJuioKipYWilhiGEEJWb1DAqL4PBAICSnWlld+AtX4zZlo6gYsjT5Vo6BKtX8B4W/Ns2N702F0VF7SFPqy+T1y8rkjBUSElJASD3x+0WjsS65Vg6gAriTmNLR1BxpKSk0LBhQ7Odz9nZGRcXF5L5RfUxLi4uODs7my2GsqRRrG31KwvIzs7m/Pnz1K5dGxsbG0uHI4T4mwwGAykpKfj6+mJvb2/Wc6elpZGZmam6vLOzM66urmaNoaxIwhBCCKGK1tIBCCGEsA6SMIQQQqgiCUMIIYQqkjCEEEKoIglDCCGEKpIwhBBCqCIJQwghhCqSMMqRkydP8vTTTxfZvnjxYrZu3XrfY7ds2cLo0aPLKDLrdK/3U5TeuXPnmDhxYqmO+fPfrY+PD7du3SqDyMTDJEuDWIFJkyZZOgRRybVq1YolS5aU6hj5u614JGGUM1lZWUyePJnY2FhycnIICwsjIiKCpk2bMmLECI4ePcr8+fPRarU0b96cb775hi+++ALIXxfnpZdeIiEhARsbGxYsWICXlxcZGRnMnj2bmJgY9Ho9fn5+TJ06FZ1Oh6+vLwEBAURFRTF//nxatWpl4XfA/DIyMnj77beJiopCo9HQpUsXXnnlFebOnYuTkxMvv/wyycnJdOnShdWrV/P444+zbds2Dh8+zAcffMCmTZtYt24dRqMRV1dX3nzzTby8vJg+fTppaWlcu3aNJ598ktdee83Sl2oWd+7c4fXXX+fKlStotVpatmxJcHAws2fPZufOnUyfPh17e3tiYmK4efMm/v7+uLq6cvjwYVJSUggLC8PPz4/p06eb/m4LZGVl8dZbb3HlyhXS0tJwcnJi/vz5NGnShCFDhuDi4kJsbCyDBg1iyJAhFnwXRHGkSaqcSUxM5IUXXmDbtm2EhoaydOlS077U1FSmTp3KvHnz2LZtGx07diQpKcm0/9q1a8yYMYMdO3bQvn17li9fDsC7775Ly5Yt2bJlC1u3biU1NZWVK1cCoNfr6datG/v27auQyQIgLCwMV1dXduzYwebNm4mOjmbFihUEBQVx7NgxACIjI6lduzbffPMNAIcOHSIoKIhTp06xdetWwsPD2bp1KyNHjmT8+PGmc2dnZ7Nr164KkywA9u/fz507d9i2bRsREREAxMfHFypz8eJFVq9ezdq1a1mxYgWOjo6sX7+eoUOH8umnn97z3MeOHaNatWps2LCBffv24evrS3h4uGl/tWrV2L17tySLckoSRjnToEED2rRpA0CzZs0Ktft+//33eHl50axZMwBCQkIKrXLZunVr08qbzZs3Nx175MgRNmzYQO/evenTpw9nz54lJibGdFz79u3L/Los6dixYzz//PNoNBrs7OwIDQ3l2LFjtGvXjqSkJG7cuEFkZCRjx47l66+/Jjc3l++++46uXbty5MgRrly5QmhoKL1792bevHmkp6eTlpYGQLt27Sx7cWWgXbt2/PLLLwwZMoRPPvmEYcOG4enpWahMt27dsLW1pXbt2jg6OtKlSxcAPD09Te9NcXr06EFISAhr1qwhLCyMU6dOkZWVZdpf0f8WrZ00SZUztra2pp81Gg1/XhvSxsaGv64VqdX+kfN1Ol2xxxqNRhYvXoyXlxcA6enpaDQaU1lHR0fzXkQ5YzQaC12v0WgkLy8PrVbLk08+ydGjRzl79izvv/8+H3/8MXv37qVt27Y4OTlhNBrp3bu3qQZhNBpJTk7GxcUFqJjvXYMGDdi/fz8nT57kxIkTvPjii7zzzjuFytjZ2RV6/ue/vfv54osv2LhxI4MHD6ZXr164uroWqr1UxPezIpEahhV59NFHiYuLIyoqCoB9+/YV+fAvTufOnVm1ahWKopCbm8vYsWNZu3btwwi5XOjcuTNr1641Xf/GjRvp1KkTAEFBQXz22Wd4e3tjZ2fH448/zsKFCwkKCjIdu2vXLpKTkwFYt24dw4YNs9i1PAxffPEFr7/+Op07d+a1116jc+fOXLx40SznPn78OCEhIfTv35/GjRtz6NChMruJkTA/SRhWxNXVlYULFzJt2jRCQkI4fvw4Op0OBweH+x43Y8YMsrKy6NWrF7169cLb25uRI0c+pKgt74033uDWrVum62/cuDFjxowBwM/Pj+TkZFMC6dy5Mzdu3MDf39/0fNSoUQwfPpxevXqxc+dOli1bVmKStmbPPvssBoOBnj170qdPHzIyMvDx8THLuYcPH86GDRvo1asXgwcPpmXLlly9etUs5xZlT+6HYUUyMzP573//y4QJE3BwcODChQuMHj2ayMjICv0BJoQoH6QPw4o4Oztja2tLv3790Ol06HQ6PvjgA0kWQoiHQmoYQgghVJE+DCGEEKpIwhBCCKGKJAwhhBCqSMIQJkuXLsXHx6fIo2XLlnTs2JEhQ4awbdu2hxpTeno6Pj4+hZaK2LJlCz4+PqxateqBzrlz506uXbtmpgj/0Lt3b1XDT4cMGYKPjw/p6emlfo34+Hh8fHz497///SAh3pe/v7/MtBb3JaOkRBEBAQE0b97c9DwvL49bt26xZ88epk6dSmxsLJMnT7ZYfM2bN2f8+PE88sgjpT523rx5fPbZZyUuFy+EKEoShigiMDCQPn36FNk+YsQIQkJC+PTTTxkwYAD16tWzQHT5CePPCa00bt68aeZohKg8pElKqNaoUSMCAgIwGAwcP37c0uEIIR4ySRiiVOrUqQNgWpG0oD9hz549jBgxglatWtGtWzdTH0FmZibz588nMDAQX19funTpwqxZs4r9ph8fH8+UKVPo1KkTbdu2Zfz48Vy/fr1IuXv1YURFRTF58mSeeOIJ2rZtS0hICBEREaZFGP39/fnyyy+B/OUvCpb/AFAUhXXr1hESEkLr1q157LHHGDNmTLFrKGVnZ7Nw4UL8/f1p3bo1AwYM4Lvvviv9m/kner2e1atXM2DAANq1a4evry/dunVj5syZ97xT3VdffUWvXr1o1aoV//rXv/j444/R6/VFyl25csX0vvr6+vLUU0/ds6wQ9yNNUqJUCtb9KUgcBcLCwnBzc2PIkCHEx8fToEEDMjIyeO6554iJicHPz4+goCDi4+PZuHEjkZGRrF+/Hjc3NyD/PiChoaGmdZzq1q1LZGSk6jWvvv32W8aMGYPBYCAgIIC6dety5MgRZsyYwfXr15k4cSJDhw7lyy+/JCoqioEDB9KkSRPT8dOmTWPbtm00bdqU0NBQ7t69y549ewgNDeXjjz/Gz88PyF+tdtSoUZw6dYrWrVvTvXt3zp07x/Dhw0tc0+t+Xn31Vfbt20e7du0YMGAAubm5HD9+nA0bNnDhwgU2b95cqPxPP/3E4cOH6datG35+fhw7doyFCxcSFRXFokWLTOUuXLjAsGHDyM7OJigoiLp16/L999+zcOFCvvvuOz7++GNsbGweOG5RyShC/G7JkiWKt7e3snnz5mL3nz17VmnRooXSunVr5ebNm4qiKMrmzZsVb29v5Z///KeSlZVVqPxbb72leHt7K2vXri20/cCBA4q3t7cyceJE07apU6cq3t7eypYtW0zb7ty5ozz//POKt7e38vzzz5u2F7zmypUrFUVRlLy8PMXf319p1aqV8uOPP5rKZWdnK7169VKaN2+u3LhxQ1EURZk2bZri7e2tXLx40VRu9+7dire3t/LKK68oer3etP3q1atKhw4dlC5duig5OTmKoihKRESE4u3trbz++uuKwWAwlZ07d67i7e2teHt73+cdzldwTbdv31YURVFOnz6teHt7K6+++mqhcnq9Xnn66acVb29vJTY2VlEURbl27ZrpdVavXm0qe/fuXWXo0KGKt7e3cvz4cUVRFMVoNCpPP/200qpVK+XcuXOFzv3uu+8W+d1069ZNadeuXYnxi8pLmqREEQcOHGDp0qWmx6JFi5g4cSKDBw8mLy+PqVOnUqNGjULHdO3atdA37Ly8PLZu3UrTpk0ZPHhwobIBAQE8+uij7N+/n8zMTHJzc/nqq69o2rQpISEhpnKOjo5MmTKlxHh/+ukn4uPj6d27N23btjVtr1KlCtOnT2fChAnk5OTc8/iCu8rNmDGj0H0dGjRoQGhoKElJSaY78e3atQuNRsOrr75a6F4kL7/8MlWrVi0x1uK4u7szZ86cIvfA1ul0phs0/bUJz9PTs9D7am9vbxq5tmPHDgDOnDlDTEwM/fr1w9fXt9DxkyZNwtbWli1btjxQzKJykiYpUcTBgwc5ePCg6bmtrS2urq488cQTDB48mM6dOxc55q8jpi5fvkxWVhYGg6HQbWYL5OTkYDAYiI6OxtXVlaysrCIfagC+vr6FbipVnIL7gxQ3zLZTp06mpcvv5cKFC1SpUqXQrUL/fB0Aly5d4sknnyQqKoq6detSs2bNQuXs7Oxo2bIlJ06cuO9rFcfd3Z2QkBDy8vK4cOECly9f5urVq1y6dMmUqIxGY6Fj2rRpU6QpqWXLlmi1WtP7ceHCBSC/GbG434GTkxPR0dEoiiILWApVJGGIIt57771ih9XeT5UqVQo9L5iUFhsby7Jly+553O3bt00fVk5OTkX229jYFLoNbXEKXqukcveSkZFBXl5eiXEWvNZfk0WBgrvwPYj169fz4Ycfmm7UVK1aNdq0aYOXlxdnzpwpcqfFWrVqFTmHra0tVapUMd3ytOB9iYyMJDIy8p6vfefOnQd+70TlIglDlImCD//evXvz/vvv37fsr7/+CuR/cP+VoijcvXv3vscX3Nbzzp07Rfbp9XoURSlyS9G/Hu/k5MSRI0fu+zqQ/0FeXJxAoXtTl8aePXuYNWsWPj4+zJo1i5YtW+Lh4QHArFmzOHPmTJFjipslnpmZyd27d4vcPnb27Nn069fvgWIT4s+kD0OUicaNG2NnZ8eFCxeKfDsGWLVqFf/9739JTU3F09OTqlWrcvr06SLlfvnlF7Kzs+/7Wt7e3gCcPXu2yL49e/bQpk0b08zu4ppefHx8SExMJCUlpci+w4cPs2jRIlMzT8uWLUlISCgy3NdgMHDp0qX7xnkvO3fuBGDBggUEBgaakgXk19CAIu/huXPnipznxx9/NMVYcF0A58+fL1JWr9czZ84c1qxZ80Axi8pJEoYoE1WqVKFnz5788ssvrFy5stC+kydP8v7777N582ZcXFywtbXl6aef5urVq4XK5ubmsmDBghJf67HHHsPDw4Nt27YV+tDOzc1l1apVaLVa07DYgk7tP89BCAkJQVEU/vOf/5Cbm2vanpyczFtvvcUnn3xi+rZe0Ck/Z86cQudYvnw5N27cUP3+/FlBc95fj9+6dSunTp0C8gcR/FlMTAx79uwxPc/MzDTdTKugOfGxxx6jfv36REREFEnGn3zyCStXrjT1cwihhjRJiTIzbdo0Tp8+zdy5czl48CCtW7cmKSmJr776Cp1Ox7vvvmsaaTR58mS+/fZb5syZw/Hjx/Hy8uLbb78lLS2tSP/IXxWca/To0YSGhtK9e3dq1qzJkSNHiIuL4/XXXzfNGyn4/5w5c+jUqRPjx4+nT58+HDp0iH379hEdHU2XLl3Iy8tjz549pKWl8eqrr+Lp6QlAz5492bdvH3v37uXy5cv4+fnxyy+/cOLECerVq8dvv/1W6vfpmWeeYdeuXYwfP57g4GCcnZ05d+4cp06dombNmty8edM0UbKAp6cnU6ZM4cCBA1SvXp3Dhw8THx/PSy+9ROvWrYH8/p+5c+cyatQonn/+eQICAmjQoAHnz5/nxIkT1K9fn1deeaXU8YrKS2oYoszUqFGDjRs3Mnz4cJKSklizZg3ff/89/v7+bNy4kY4dO5rKuri4sG7dOkJDQ4mOjmbDhg3UqlWLVatW3bf/oUCnTp1Yt24dfn5+HD16lPDwcBwcHJg7dy4vvPCCqdxzzz3HE088wfnz51mzZg137txBo9GwZMkSZsyYgYODA5s2bWLPnj384x//4MMPP+Sll14q9FoLFy5kypQp5Obmsm7dOlJSUli2bBnNmjV7oPfpySefZNGiRXh6erJjxw6+/PJLcnJymDlzJp999hkAR48eLXJMWFgY58+fZ/369Tg4OBAWFsarr75aqFz79u3ZtGkTPXr04Pvvv+fzzz/n+vXrDBkyhA0bNpgmTgqhhtyiVQghhCpSwxBCCKGKJAwhhBCqSMIQQgihiiQMIYQQqkjCEEIIoYokDCGEEKpIwhBCCKGKJAwhhBCqSMIQQgihiiQMIYQQqvw/Dc9XaJ2WNkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x324 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(fit_mnlogit_sk, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are having trouble predicting the county unemployment rate similar to the national.\n",
    "\n",
    "Let's take a look at the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5493065801121275"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = fit_mnlogit_sk.predict(x_test)\n",
    "acc_mnlogit = np.mean(yhat == y_test)\n",
    "acc_mnlogit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.52"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*(acc_mnlogit - acc_mnlogit_null)/acc_mnlogit_null, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad improvement, but remember that we are only getting it correct barely more than 50% of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
