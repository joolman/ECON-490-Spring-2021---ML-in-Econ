{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alleged-deputy",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "***\n",
    "My goal is not to fit a good model.\n",
    "My goal is to show you how to implement what is covered in the slides.\n",
    "***\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "- [Preliminaries](#Preliminaries)\n",
    "- [Null Model](#Null-Model)\n",
    "- [Initialization](#Initialization)\n",
    "- [Compilation](#Compilation)\n",
    "- [Fitting](#Fitting)\n",
    "- [Evaluation](#Evaluation)\n",
    "- [Prediction](#Prediction)\n",
    "\n",
    "\n",
    "****************\n",
    "# Preliminaries\n",
    "[TOP](#Keras)\n",
    "\n",
    "Remember, standardizing your features affects the cost function; standardizing helps correctly and quickly finding the optimal solution.\n",
    "Let us grab our custom `stdz()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-alias",
   "metadata": {},
   "source": [
    "Here are the packages and functions that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# algorithms\n",
    "from tensorflow import keras\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-priest",
   "metadata": {},
   "source": [
    "# Setting the Seed....\n",
    "\n",
    "It is quite an involved process. \n",
    "Not only do we need to set the seed for `TensorFlow`, but we also need to set it for `NumPy` and in the backend because they are all used when fitting a neural network.\n",
    "\n",
    "Check out the [documentation](https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generic-stability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(490)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(490)\n",
    "tf.random.set_seed(490)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-method",
   "metadata": {},
   "source": [
    "Okay, let's load in our data.\n",
    "\n",
    "Predicting categorical data requires much more setup than the regression data.\n",
    "\n",
    "* With continuous labels, you simply proceed as we have been throughout the class up to this point.\n",
    "- Discrete labels require the data to be transformed via `OneHotEncoder()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passing-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50834, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['year']).join([\n",
    "    pd.get_dummies(df['year'], drop_first = True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['urate_bin']\n",
    "x = df_prepped.drop(columns = 'urate_bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-kenya",
   "metadata": {},
   "source": [
    "This is a step-by-step how to prepare categorical data for `OneHotEncoder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "y\n",
    "np.array(y)\n",
    "np.array(y).reshape(-1, 1)\n",
    "ohe = OneHotEncoder().fit(np.array(y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-course",
   "metadata": {},
   "source": [
    "Okay, time to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                                   train_size = 2/3,\n",
    "                                                   random_state = 490)\n",
    "x_train = x_train.apply(stdz)\n",
    "x_test  = x_test.apply(stdz)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test  = np.array(y_test).reshape(-1, 1)\n",
    "\n",
    "y_train = ohe.transform(y_train).toarray()\n",
    "y_test  = ohe.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-arrow",
   "metadata": {},
   "source": [
    "Just to reiterate how we have transformed our label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-booking",
   "metadata": {},
   "source": [
    "***********\n",
    "# Null Model\n",
    "[TOP](#Keras)\n",
    "\n",
    "We are going to have to fit the null model differently than before because it is now an `np.array()`, not a `pd.Series()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_counts = y_train.sum(axis = 0)\n",
    "yhat_null = np.argmax(y_train_counts)\n",
    "\n",
    "acc_null = y_test[:, yhat_null].sum()/y_test.sum()\n",
    "acc_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-china",
   "metadata": {},
   "source": [
    "*****************\n",
    "# Initialization\n",
    "[TOP](#Keras)\n",
    "\n",
    "I would not recommend actually fitting this model.\n",
    "This is purely for expositional purposes.\n",
    "\n",
    "I am going to show you how to add activation functions in multiple ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For leaky ReLU and to show you how to adjust hyperparameters\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-graphic",
   "metadata": {},
   "source": [
    "Let's determine our input and output `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-configuration",
   "metadata": {},
   "source": [
    "Okay, let's define our first neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape = x_train.shape[1]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(200, activation = LeakyReLU(alpha = 0.1))) \n",
    "model.add(keras.layers.Dense(100, activation = 'elu'))\n",
    "model.add(keras.layers.Dense(100, activation = keras.layers.ELU(alpha=1.0))) # alpha = 1 is default\n",
    "model.add(keras.layers.Dense(y_train.shape[1], activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-cambodia",
   "metadata": {},
   "source": [
    "Want to see something crazy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-preservation",
   "metadata": {},
   "source": [
    "Holy parameters, Batman!\n",
    "\n",
    "Let's see how we got so many:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense - input layer\n",
    "(1 + x_train.shape[1])*300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_1\n",
    "(1 + 300)*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_2\n",
    "(1 + 200)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_3\n",
    "(1 + 100)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_4 - output layer\n",
    "(1 + 100)*y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-intelligence",
   "metadata": {},
   "source": [
    "Here is an alternative way to define a sequential NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = x_train.shape[1]),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.Dense(200, activation = LeakyReLU(alpha = 0.1)),\n",
    "    keras.layers.Dense(100, activation = 'elu'),\n",
    "    keras.layers.Dense(100, activation = keras.layers.ELU(alpha=1.0)),\n",
    "    keras.layers.Dense(y_train.shape[1], activation = 'softmax')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-creation",
   "metadata": {},
   "source": [
    "*********************\n",
    "# Compilation\n",
    "[TOP](#Keras)\n",
    "\n",
    "I am going to show you three different ways to compile the model:\n",
    "\n",
    "1. the easy way\n",
    "2. with a custom optimizer\n",
    "3. with a custom optimizer and custom learning rate\n",
    "\n",
    "The easy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', # training data\n",
    "             metrics = ['accuracy', 'categorical_crossentropy'], # validation data\n",
    "             optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-valve",
   "metadata": {},
   "source": [
    "Custom optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default RMSprop values\n",
    "model.compile(loss = 'categorical_crossentropy', # training data\n",
    "             metrics = ['accuracy'], # validation data\n",
    "             optimizer = keras.optimizers.RMSprop(learning_rate = 0.001,\n",
    "                                                 rho = 0.9,\n",
    "                                                 momentum = 0.0,\n",
    "                                                 epsilon = 1e-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-western",
   "metadata": {},
   "source": [
    "Now we shall fit a custom learning rate schedule.\n",
    "The default values for an exponential decay learning schedule is too extreme for our setting.\n",
    "We are going to do some math to adjust the default values.\n",
    "\n",
    "When we fit, we will have:\n",
    "\n",
    "- all the training data over batches of size 32 (the default)\n",
    "- 20% validation_fraction\n",
    "- 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide by batch size\n",
    "# multiply by 1 minus validation size\n",
    "# multiply by number of epochs\n",
    "x_train.shape[0]/32*(1-0.2)*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "lr_exp = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 0.1,\n",
    "    decay_steps = 100000,\n",
    "    decay_rate = 0.96)\n",
    "\n",
    "lr_exp = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 0.1,\n",
    "    decay_steps = 5000,\n",
    "    decay_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', # training data\n",
    "             metrics = ['accuracy'], # validation data\n",
    "             optimizer = keras.optimizers.RMSprop(learning_rate = lr_exp,\n",
    "                                                 rho = 0.9,\n",
    "                                                 momentum = 0.5,\n",
    "                                                 epsilon = 1e-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-excess",
   "metadata": {},
   "source": [
    "*********\n",
    "# Fitting \n",
    "[TOP](#Keras)\n",
    "\n",
    "Before we can fit our final model, we will set up early stopping.\n",
    "This is the same idea as in boosting ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "es = keras.callbacks.EarlyStopping(patience = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-journalist",
   "metadata": {},
   "source": [
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 30,\n",
    "                   validation_split = 0.2,\n",
    "                   callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-lending",
   "metadata": {},
   "source": [
    "We can take a look at the performance of training over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history\n",
    "train_results = pd.DataFrame(history.history)\n",
    "train_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-listening",
   "metadata": {},
   "source": [
    "And plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results.plot()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-bracket",
   "metadata": {},
   "source": [
    "***************\n",
    "# Evaluation\n",
    "[TOP](#Keras)\n",
    "\n",
    "Evaluation is perhaps one of the easiest parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = model.evaluate(x_test, y_test)\n",
    "model_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-model",
   "metadata": {},
   "source": [
    "Let's save our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nn = model_perf[1]\n",
    "acc_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-potato",
   "metadata": {},
   "source": [
    "Yikes.\n",
    "What was the null accuracy again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-example",
   "metadata": {},
   "source": [
    "What was the percetage point gain from the null model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nn - acc_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-stand",
   "metadata": {},
   "source": [
    "Well... at least it is positive..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-superintendent",
   "metadata": {},
   "source": [
    "****************\n",
    "# Prediction\n",
    "[TOP](#Keras)\n",
    "\n",
    "And now for some fancy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test.iloc[0:5, :])\n",
    "yhat\n",
    "np.argmax(yhat, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
