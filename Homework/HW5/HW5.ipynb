{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neither-classic",
   "metadata": {},
   "source": [
    "## Homework 5 - Forest Through the Trees\n",
    "### Your Name\n",
    "\n",
    "**COLLABORATED WITH:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _**\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "**Submit a PDF export of your notebook (100% PENALTY IF NO PDF IS SUBMITTED)** \n",
    "\n",
    "* File > Export Notebook to HTML (you cannot upload .html to Compass), open .html in browser, print to PDF\n",
    "    - **_Ensure your code is not cut off_**\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-leonard",
   "metadata": {},
   "source": [
    "#### Table of Contents\n",
    "\n",
    "- [Intuition](#Intuition)\n",
    "    - [[5 Points] HoML Ch7 Q1](#[5-Points]-HoML-Ch7-Q1)\n",
    "- [Theory](#Theory)\n",
    "    - [[5 Points] Decision Trees](#[5-Points]-Decision-Trees)\n",
    "    - [[5 Points] Random Bags of Forests](#[5-Points]-Random-Bags-of-Forests)\n",
    "    - [[5 Points] Boosting - Gotta go fast!](#[5-Points]-Boosting---Gotta-go-fast!)\n",
    "    - [[9 Points] Ensembles](#[9-Points]-Ensembles)\n",
    "- [Application](#Application)\n",
    "    - [[0 Points] Preliminaries](#Preliminaries)\n",
    "    - [[4 Points] Null Model](#[4-Points]-Null-Model)\n",
    "    - [[14 Points] Decision Tree](#[14-Points]-Decision-Tree)\n",
    "    - [[9 Points] Random Forest](#[9-Points]-Random-Forest)\n",
    "    - [[12 Points] AdaBoosting](#[12-Points]-AdaBoosting)\n",
    "    - [[14 Points] XGBoost](#[14-Points]-XGBoost)\n",
    "    - [[13 Points] Stacking](#[13-Points]-Stacking)\n",
    "    - [[5 Points] Comparison](#[5-Points]-Comparison)\n",
    "\n",
    "\n",
    "***********************************************************************************************\n",
    "# Intuition\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "**Points are not awarded for correct answers**. \n",
    "Instead, points are awarded for explainations of why you are correct or why you are wrong.\n",
    "You must attempt to answer the question to receive any points.\n",
    "Points for intuition questions are pass/fail.\n",
    "\n",
    "Answers such as \"I am correct/wrong\" or \"because the textbook says so\" are invalid. \n",
    "Show us you know what you are talking about: explain.\n",
    "\n",
    "\n",
    "## [5 Points] HoML Ch7 Q1\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "\n",
    "If you have trained five different models on the exact same training data, and they all achieve 95% precision, is there any chance that you can combine these models to get better results? If so, how? If not, why?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "recorded-imagination",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-advance",
   "metadata": {},
   "source": [
    "Why are you correct or wrong?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "determined-street",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-finland",
   "metadata": {},
   "source": [
    "************\n",
    "# Theory\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "\n",
    "*********\n",
    "\n",
    "## [5 Points] Decision Trees\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "Why do we like decision trees?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "nasty-sessions",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "persistent-slovak",
   "metadata": {},
   "source": [
    "*********\n",
    "\n",
    "## [5 Points] Random Bags of Forests\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "What is the difference between bagging and random forests?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fabulous-rebound",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eligible-amino",
   "metadata": {},
   "source": [
    "*********\n",
    "\n",
    "## [5 Points] Boosting - Gotta go fast!\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "What is the biggest concern in boosting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "temporal-programming",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-coating",
   "metadata": {},
   "source": [
    "*********\n",
    "\n",
    "## [9 Points] Ensembles\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "What are the three methods of ensemble learning we covered in this course?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "recovered-radio",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "provincial-serbia",
   "metadata": {},
   "source": [
    "**************\n",
    "\n",
    "# Application\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "\n",
    "**************\n",
    "## Preliminaries\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "Here you go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# alogirthms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-launch",
   "metadata": {},
   "source": [
    "Modify \n",
    "\n",
    "the \n",
    "\n",
    "cell \n",
    "\n",
    "below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/homework data/hw_data.pkl')\n",
    "df.set_index(['county', 'ind1990', 'occ2010'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xgboost\n",
    "le = LabelEncoder()\n",
    "\n",
    "x = df.drop(columns = 'degree')\n",
    "y = df['degree']\n",
    "le.fit(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.05, random_state = 490)\n",
    "\n",
    "x_train = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "y_train = le.transform(y_train)\n",
    "y_test  = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-territory",
   "metadata": {},
   "source": [
    "**************\n",
    "## [4 Points] Null Model \n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "\n",
    "**[4 points]** Determine which class we will be predicting in the null model and evaluate (save) then print the null model accuracy\n",
    "\n",
    "*Hints to create* `yhat`:\n",
    "\n",
    "1. use `np.unique(..., return_counts = True)`\n",
    "2. create an object by using a dictionary comprehension on the zipped output from the previous step\n",
    "3. use `max()` to obtain the key from the dictionary created in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-livestock",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-orange",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-shipping",
   "metadata": {},
   "source": [
    "************\n",
    "## [14 Points] Decision Tree\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-scoop",
   "metadata": {},
   "source": [
    "Use cross-validation to idenitfy the optimal number of leaves\n",
    "\n",
    "- **[2 points]** Use a parameter grid for `max_leaf_nodes` over a range from 2 to 9 inclusive.\n",
    "- **[2 points]** Initialize the decision tree with a `random_state` of 490\n",
    "- **[2 points]** Use five-fold grid search cross-validation with an accuracy scoring metric\n",
    "- **[2 points]** Save and print the optimal number of terminal nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-investigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ruled-surveillance",
   "metadata": {},
   "source": [
    "Produce a figure of the decision tree.\n",
    "\n",
    "- **[2 points]** Refit the decision tree on the entire training data\n",
    "- **[2 points]** produce a figure of the decision tree similar to in lecture specifying...\n",
    "    - a figure dpi of 300\n",
    "    - `class_names = le.inverse_transform([0, 1, 2])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "expired-application",
   "metadata": {},
   "source": [
    "- **[2 points]** Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "architectural-distinction",
   "metadata": {},
   "source": [
    "*************\n",
    "## [9 Points] Random Forest\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "- **[2 points]** Fit a random forest specifying (-1 point per missing argument)\n",
    "    - 500 estimators\n",
    "    - a random state of 490\n",
    "    - the appropriate max features\n",
    "    - out of bag scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-summer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "subtle-pavilion",
   "metadata": {},
   "source": [
    "- **[2 points]** Print the out of bag score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-combination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-carry",
   "metadata": {},
   "source": [
    "- **[2 points]** Print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-footwear",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "popular-tumor",
   "metadata": {},
   "source": [
    "- **[1 point]** Using the feature importances, create `df_plot` following lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-patrol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accepting-tobacco",
   "metadata": {},
   "source": [
    "- **[2 points]** Produce the feature importance figure\n",
    "    - use `seaborn` to produce a barplot\n",
    "    - add a title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-sarah",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lyric-restaurant",
   "metadata": {},
   "source": [
    "*********\n",
    "# [12 Points] AdaBoosting\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "Use cross-validation to fit an AdaBoosted decision tree.\n",
    "\n",
    "- **[2 points]** Identify `n_estimators` to the nearest multiple of 25 and use a grid over `learning_rate` of `[0.1, 0.5, 1, 1.5]`\n",
    "- **[2 points]** Initialize the AdaBoost with `base_estimator` set to a decision tree with a max depth of 1\n",
    "- **[2 points]** Perform a five-fold grid search cross-validation using an accuracy metric\n",
    "- **[2 points]** Print the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-torture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "manual-sigma",
   "metadata": {},
   "source": [
    "- **[2 points]** Refit the AdaBoost with the optimal parameters\n",
    "- **[2 points]** Save and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-newsletter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "compact-albania",
   "metadata": {},
   "source": [
    "*********\n",
    "## [14 Points] XGBoost\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "- **[4 points]** Following lecture, define `x_train_train`, `x_train_test`, `y_train_train`, and `y_train_test` using an 80% train size and a random state of 490."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "honey-bouquet",
   "metadata": {},
   "source": [
    "**[4 points]** Fit a extreme gradient boosted decision tree\n",
    "\n",
    "1. Initialize with the following arguments\n",
    "    - 200 estimators\n",
    "    - a max depth of 2\n",
    "    - a learning rate of 1/2\n",
    "    - a random state of 490\n",
    "    - `use_label_encoder = False`\n",
    "2. Fit on the training training data...\n",
    "3. using an evaluation set as the tuple of the testing training data...\n",
    "4. with 4 early stopping rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "color-landscape",
   "metadata": {},
   "source": [
    "- **[2 points]** Save and print the best iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-management",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "downtown-rotation",
   "metadata": {},
   "source": [
    "- **[2 points]** Refit the classifier **using the best iteration identified above** as the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-gross",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "established-denial",
   "metadata": {},
   "source": [
    "- **[2 points]** Save and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handy-liability",
   "metadata": {},
   "source": [
    "***********\n",
    "## [13 Points] Stacking\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "\n",
    "- **[1 point]** print the accuracy for the random forest, the AdaBoost, and the XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aerial-chrome",
   "metadata": {},
   "source": [
    "This problem requires referencing the `sklearn` documentation for [`StackingClassifier()` at this link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier). \n",
    "\n",
    "Because the random forest, AdaBoost, and XGBoost are all fit using decision trees, they all make predictions in a similar way, therefore, are not very diverse in the decision-making. \n",
    "We will pair the best of the decision tree models with a Gaussian naive bayes and a linear SVC.\n",
    "These three models will be aggregated with a logistic regression.\n",
    "\n",
    "We do not need to create two separate training sets because `StackingClassifier()` has built in cross-validation.\n",
    "\n",
    "- **[10 points]** Fit a stacked ensembling on the training data specifying estimators of (2 points each)\n",
    "    1. The best performing decision-tree based model\n",
    "    2. a Gaussian naive bayes\n",
    "    3. a linear SVC\n",
    "- with a final estimator of\n",
    "    4. logit with a 'saga' solver\n",
    "    5. using five-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-captain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-capability",
   "metadata": {},
   "source": [
    "- **[2 points]** Save and print hte accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-barrel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "breeding-nicholas",
   "metadata": {},
   "source": [
    "**********\n",
    "## [5 Points] Comparison\n",
    "[TOP](#Homework-5---Forest-Through-the-Trees)\n",
    "\n",
    "- **[1 point]** However you see best, print out the accuracy from the five models fit in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-election",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gross-questionnaire",
   "metadata": {},
   "source": [
    "- **[2 points]** What was the best model from this assignment?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "leading-dover",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "august-bumper",
   "metadata": {},
   "source": [
    "- **[2 points]** What was the percentage point (not percent, what we normally do) improvement in accuracy of the best model relative to the null model?\n",
    "\n",
    "*Hint: accuracy has units of percentage points.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-lunch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
