{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1 - Yeehaw! Data Wrangling!\n",
    "### Your Name\n",
    "\n",
    "**COLLABORATED WITH:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _**\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "**Submit a PDF export of your notebook (100% PENALTY)** \n",
    "\n",
    "* Option 1 - File > Export Notebook to PDF\n",
    "* Option 2 - File > Export Notebook to HTML (you cannot upload .html to Compass), open .html in browser, print to PDF\n",
    "    - You need to use this option if you have math with `\\begin{align} ... \\end{align}`.\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "#### Table of Contents\n",
    "- [Overview](#Overview)\n",
    "- [[10 Points] Preliminaries](#[10-Points]-Preliminaries)\n",
    "- [ACS](#ACS)\n",
    "    - [[15 Points] Prep](#[15-Points]-Prep)\n",
    "    - [[5 Points] Creating Keys](#[5-Points]-Creating-Keys)\n",
    "    - [[15 Points] Grouped Features](#[15-Points]-Grouped-Features)\n",
    "    - [[10 Points] Individual Features](#[10-Points]-Individual-Features)\n",
    "    - [[5 Points] Labels](#[5-Points]-Labels)\n",
    "- [[10 Points] FHFA](#[10-Points]-FHFA)\n",
    "- [[25 Points] Transformations](#[25-Points]-Transformations)\n",
    "- [[5 Points] Pickling](#[5-Points]-Pickling)\n",
    "\n",
    "# Overview\n",
    "\n",
    "**DOWNLOAD ALL DATA INTO THE SAME FOLDER**\n",
    "\n",
    "We will be primarily using data from the 2016 American Community Survey (ACS) sourced from https://ipums.org/. \n",
    "You will need to **create a free account** to access the data.\n",
    "\n",
    "ACS Steps:\n",
    "\n",
    "* On the USA IPUMS page either click the Get Data button or the Select Data tab\n",
    "* Click change samples. Ensure only ACS 2016 is selected (You can click the Default sample from each year button to unselect the preselected)\n",
    "* Select variables\n",
    "    - STATEFIP, COUNTYFIP, PUMA, DENSITY, NCHILD, SEX, AGE, RACE, HISPAN, EDUC, EMPSTAT, OCC2010, IND1990, UHRSWORK, INCWAGE\n",
    "* View cart\n",
    "* For reducing the size of the extract, **unselect** the following preselected variables (we need the others)\n",
    "    - YEAR, SAMPLE, CBSERIAL, HHWT, CLUSTER, STRATA\n",
    "* CREATE DATA EXTRACT\n",
    "* DATA FORMAT > Change > Comma delimited (.csv) > SUBMIT\n",
    "* Provide a description of the extract like: \"AML in Econ homework data\"\n",
    "* SUBMIT EXTRACT\n",
    "\n",
    "**SUPER IMPORTANT** Each variable (continuous or categorical) has an associated code to it. For an example of a codebook you will need, click on the EDUC variable, go to the codes tab, and select the Detailed codes (44 categories) *and* Case-count view.\n",
    "\n",
    "To extract:\n",
    "- **Windows Users**: Use 7zip to extract (like I do) https://www.7-zip.org/download.html\n",
    "- **MAC Users**: In your terminal, navigate to the location of your file. Type `gunzip usa_000XX.csv.gz`\n",
    "\n",
    "Because surveys tend to ask a let of yes or no questions, they primarily consist of dummy variables. \n",
    "We are going to add to our list of continuous variables by merging county-level housing data from the Federal Housing Finance Agency (FHFA) https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index-Datasets.aspx.\n",
    "\n",
    "FHFA Steps:\n",
    "\n",
    "* Download the counties developmental index\n",
    "* Open it and notice the preamble and where the data begins\n",
    "\n",
    "***\n",
    "\n",
    "Because we will be demonstrating different techniques for different types of labels in this class, we will create three different types of label that can be interchangeably used as features. \n",
    "\n",
    "* Labels\n",
    "    - wage (continuous)\n",
    "    - full-time dummy (binary)\n",
    "    - degree $\\in \\{\\leq$ HS, some college, $\\geq$ BA$\\}$\n",
    "- Features\n",
    "    * public use micro area (puma) unemployment rate\n",
    "    * percent of workers in an occupation with a bachelor's degree\n",
    "    * average industry wages\n",
    "    * experience = age - years of schooling - 6\n",
    "    * female indicator\n",
    "    * any kids at home indicator\n",
    "    * black indicator\n",
    "    * hispanic indicator\n",
    "    * 2000 based house price index\n",
    "\n",
    "# [10 Points] Preliminaries\n",
    "\n",
    "- **[5 points]** Import `pandas`, `numpy`, `matplotlib.pyplot`, `seaborn` and `os`.\n",
    "- **[1 point]** Change your working directory to where your data are saved.\n",
    "- **[2 points]** List the files in the directory\n",
    "- **[2 points]** Set up `seaborn` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "# ACS\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "\n",
    "## [15 Points] Prep\n",
    "- **[1 point]** Load in the data as an object named `acs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[2 point]** Holding down shift is annoying. Make all of the variables lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the data set such that:\n",
    "* **[2 points]** individuals are not in group quarters\n",
    "* **[2 points]** individuals are working age $\\in [16, 65)$\n",
    "* **[2 points]** there are no military or unemployed with no worth experience in the last five years occupations\n",
    "* **[2 points]** there are no N/A, military or last worked 1984 or earlier industries\n",
    "* **[2 points]** there are no N/A education values (*hint: EDUCD*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[2 points]** drop the `gq` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## [5 Points] Creating Keys\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "We need to create geographic and individual keys that will be used for linking.\n",
    "Firstly, create the geographic keys:\n",
    "* **[1 point]** `county` - county codes\n",
    "* **[1 point]** `puma_code` - public use micro area code\n",
    "\n",
    "*Hint: counties are fully identified by a 5 digit code. The first two are the state FIPS and the last three are the county FIPS. puma codes are a 7 digit code like counties. Think of a way using middle school level math to create these codes.*\n",
    "\n",
    "*For example: Champaign county, IL and Cherokee county, AL both have county FIPS of 019, but IL has state FIPS of 17 and AL has state FIPS 1. This makes Champaign 17019 and Cherokee 1019*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals on the other hand are identified by their household `serial` number combined with the person number (`pernum`) in the household such that the last two digits are the person number. \n",
    "- **[1 point]** Using the same methodology as above, create a variable `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now\n",
    "* **[2 points]** drop columns `countyfip`, `statefip`, `puma`, `pernum`, and `serial` in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "## [15 Points] Grouped Features\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "Next we will create the following grouped features: (1) unemployment rate grouped by PUMA, (2) percent with a bachelor's degree group by occupation, and (3) average wage grouped by industry. It should take three lines each (fewer if you are a better coder than I!):\n",
    "1. create an empty temporary data frame\n",
    "2. create a variable in the temporary data frame from a lambda function applied to the acs grouped by the group variable\n",
    "3. join the temporary data frame to the ACS data by the group variable\n",
    "\n",
    "Create the variables as described above\n",
    "- **[5 points]** `puma_urate`\n",
    "- **[5 points]** `occ_ba`\n",
    "- **[5 points]** `ind_wage`\n",
    "\n",
    "*Hints: Recall that the unemployment rate is given by*\n",
    "$$unemployment\\text{ }rate = 100 \\frac{\\sum_{i=1}^N I\\{unemployed_i\\}} {\\sum_{i=1}^N I\\{labor\\text{}force_i\\}}$$\n",
    "*where $I\\{unemployed_i\\} = 1$ indicates being unemployed and $I\\{labor\\text{}force_i\\} = 1$ indicates being in the labor force.*\n",
    "\n",
    "*BECAUSE WE HAVE SURVEY DATA, WE NEED INDIVIDUAL WEIGHTS TO CALCULATE AGGREGATE STATISTICS. That means we need to multiply each element in the fraction by* `perwt` *in our code. This also needs to be done in the other two variables.*\n",
    "\n",
    "*Use logic statements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puma_urate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occ_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_wage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## [10 Points] Individual Features\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "Filter you data set such that\n",
    "- **[1 point]** all individuals are employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the `experience` variable.\n",
    "To do so, map a dictionary of all detailed education codes to years of schooling `yos`. For clarification: \n",
    "* Define one yos to start at 1st grade (set kindergarten and nursery school/preschool to zero).\n",
    "* Define from 12th grade, no diploma to Some college, but less than one year as 12 yos\n",
    "* Define bachelor's degree as 16 yos\n",
    "* Define master's degree as 18 yos\n",
    "* Define professional/doctoral degree as 20 yos\n",
    "\n",
    "One you have mapped the dictionary to the detailed education variable, create the experience variable:\n",
    "* **[5 points]** `experience` = `age` - `yos` - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the dummy features for:\n",
    "\n",
    "* **[1 point]** `female`\n",
    "* **[1 point]** `any_kids`\n",
    "* **[1 point]** `black`\n",
    "* **[1 point]** `hispanic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "## [5 Points] Labels\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "Now to create our three different labels:\n",
    "1. **[1 points]** `full_time` - works weakly greater than 35 hours\n",
    "    - *hint: logic statement made integer*\n",
    "2. **[2 points]** `degree` with values `hs or less`, `some college`, and `ba or more`\n",
    "    - *hint: use a nested* `np.where()`\n",
    "3. **[0 points]** `incwage`\n",
    "    - *hint: this hint is intentionally left blank, but by leaving a message it is now no longer blank*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the variables we need: `id`, `county`, `occ2010`, `ind1990`, `incwage`, `full_time`, `degree`, `density`, `experience`, `puma_urate`, `occ_ba`, `ind_wage`, `female`, `any_kids`, `black`, `hispanic`\n",
    "\n",
    "* **[1 point]** Trim the `acs` data frame by explicitly selecting the variables we need\n",
    "* **[1 point]** print the shape of `acs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# [10 Points] FHFA\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "* **[2 points]** Load in the HPI data as `hpi` taking into account the preamble.\n",
    "\n",
    "When you get a message that says you need the package xlrd and then you are like okay, I'll go install that and then you run the code again and then you get the message the xlsx file not support and you are like w(hy)tf not?! specify the option `engine = 'openpyxl'` inside of the pandas read function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[2 points]** Make the variables lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one line\n",
    "* **[4 points]** filter to only have 2016 data, select the FIPS code and the 2000-based hpi, and rename the selected columns with a dictionary to be `county` and `hpi` respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one line\n",
    "* **[2 points]** create the data frame `df` using an inner merge with `acs` and `hpi` on the appropriate key variable and then set the index to `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** \n",
    "# [25 Points] Transformations\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "By this point, you should have **wrangled** the data set for *all* subsequent homework assignments.\n",
    "Now it is time to clean it and deal with any necessary (logarithm) transformations.\n",
    "\n",
    "* **[1 point]** print the info from `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One variable should not be string. \n",
    "* **[1 point]** identify which variable should not be a string and convert it as a float type\n",
    "* **[4 points]** read the error and drop the troublesome value(s), then convert the variable as a float type\n",
    "* **[2 point]** print the info again to show you have handled it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Here is a helping hand. \n",
    "Only two variables need a log transformation.\n",
    "\n",
    "For the two identified variables\n",
    "* **[10 points, 1 per item over 2 figures]** produce a figure with \n",
    "    - two side-by-side histograms where the left is the raw data and the left is the data on a log axis\n",
    "    - with a tight layout\n",
    "    - with appropriate titles and x-axis labels\n",
    "    - adjust the number of bins (say 10)\n",
    "    - *hint: what is log(0)?*\n",
    "* **[2 points]** drop any observations with troublesome values\n",
    "* **[4 points]** create a new variable with the prefix `l_` and drop the original \n",
    "    - `julian` $\\rightarrow$ `l_julian`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[1 point]** reorder the variables matching the `acs` selection above with the transformed variables\n",
    "    - Order: keys, labels, continuous features, discrete features\n",
    "    - `hpi` wink, wink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "# [5 Points] Pickling\n",
    "[TOP](#Homework-1---Yeehaw!-Data-Wrangling!)\n",
    "\n",
    "* **[2 point]** First, print the head of your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[3 points]** Save the final data frame to a pickle with a fancy name like \"hw_data.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
