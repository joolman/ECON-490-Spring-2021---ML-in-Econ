{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faced-explanation",
   "metadata": {},
   "source": [
    "##### Homework 3 - Classy Validity\n",
    "### Your Name\n",
    "\n",
    "**COLLABORATED WITH:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _**\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "**Submit a PDF export of your notebook (100% PENALTY IF NO PDF IS SUBMITTED)** \n",
    "\n",
    "* File > Export Notebook to HTML (you cannot upload .html to Compass), open .html in browser, print to PDF\n",
    "    - You need to use this option if you have math with `\\begin{align} ... \\end{align}`.\n",
    "    - Ensure your code is not cut off\n",
    "\n",
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "* [Theory](#Theory)\n",
    "    - [[30 Points] Bayes Theorem](#[30-Points]-Bayes-Theorem)\n",
    "    - [[10 Points] Sigmoid Log-Odds](#[10-Points]-Sigmoid-Log-Odds)\n",
    "* [Application](#Application)\n",
    "    - [[16 Points] Preliminaries](#[16-Points]-Preliminaries)\n",
    "    - [[4 Points] Null Model](#[4-Points]-Null-Model)\n",
    "    - [[17 Points] Logistic Regression](#[17-Points]-Logistic-Regression)\n",
    "    - [[14 Points] KNN](#[14-Points]-KNN)\n",
    "    - [[4 Points] Gaussian Naive Bayes](#[4-Points]-Gaussian-Naive-Bayes)\n",
    "    - [[5 Points] Comparison](#[5-Points]-Comparison)\n",
    "\n",
    "**************\n",
    "# Theory\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "\n",
    "In this section we will show...\n",
    "\n",
    "1. Provide an application on Bayes theorem on COVID testing\n",
    "    - **_Bayes theorem questions are common interview questions_**\n",
    "2. Show how to rearrange the logit sigmoid to produce log-odds.\n",
    "\n",
    "***********************\n",
    "## [30 Points] Bayes Theorem\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "\n",
    "\n",
    "**DISCLAIMER:** FOLLOW ALL CDC AND UNIVERSITY COVID POLICIES AND GUIDELINES. COVID IS CONTAGIOUS BEFORE YOU ARE SYMPOTMATIC ([Walsh et al., 2020](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7323671/)). You can have COVID before you test positive.\n",
    "\n",
    "***\n",
    "\n",
    "We are interested in evaluating the probability of having COVID at UIUC given that your receive a positive test.\n",
    "\n",
    "Our university uses a pooled nucleic acid amplication test (NAAT) according to [McKinely Health Center](https://www.mckinley.illinois.edu/travel-testing-covid-19#:~:text=The%20campus%2Dbased%20saliva%20test,in%20less%20than%2024%20hours.&text=Nasal%20testing%20is%20available%20within,campus%20(M%2DF)%20at%20CRCE.).\n",
    "These tests have a sensitivity of ~85% and a specificity of ~99% according to [Butler-Laporte et al. (2021)](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2775397?guestAccessKey=8058e841-bc18-4398-a251-54087a84297f&utm_source=silverchair&utm_medium=email&utm_campaign=article_alert-jamainternalmedicine&utm_content=olf&utm_term=011521).\n",
    "Assume that ~50,000 individuals are testing (some students are likely to have not come to campus, however, faculty, administration, and staff must be tested).\n",
    "Furthermore, assume that 250 of these individuals truly have COVID.\n",
    "\n",
    "This Bayes table is created using the above numbers with some rounding:\n",
    "\n",
    "|               | Negative (neg) | Positive (pos) | Total     |\n",
    "|---------------|----------------|----------------|-----------|\n",
    "| No COVID (NC) | 49250          | 500            | **49750** |\n",
    "| COVID (C)     | 38             | 212            | **250**   |\n",
    "|               |                |                |           |\n",
    "| **Total**     | **49288**      | **712**        | **50000** |\n",
    "\n",
    "\n",
    "We are firstly interested in the question: Given that an individual has tested positive, what is the probability they have COVID? Recall Bayes theorem is given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    p(C|pos) & = \\frac{P(pos|C)P(C)}{P(pos)}\\\\\n",
    "    & = \\frac{P(pos|C)P(C)}{P(pos|C)P(C) + P(pos|NC)P(NC)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "1. **[10 points]** Using **either** LaTeX or Python, verify $P(pos) = P(pos|C)P(C) + P(pos|NC)P(NC)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-murray",
   "metadata": {},
   "source": [
    "Solution LaTeX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-style",
   "metadata": {},
   "source": [
    "2. **[8 points]** Using either LaTeX or Python, verify $p(C|pos) = \\frac{P(pos|C)P(C)}{P(pos)}$. If you choose to use LaTeX, print out the answer for fun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-religious",
   "metadata": {},
   "source": [
    "Solution LaTeX:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-split",
   "metadata": {},
   "source": [
    "We are finally interested in the probability of *not* having COVID, given an individual has tested positive twice in a row.\n",
    "\n",
    "3. **[12 points]** Evaluate $P(NC|2pos)$.\n",
    "\n",
    "*Hints:*\n",
    "- *You cannot directly evalute this value from the Bayes table. You need the extended Bayes theorem*\n",
    "- $P(2pos) \\neq P(pos)^2$\n",
    "- $P(2pos|NC) = P(pos|NC)^2$\n",
    "- *Use LaTeX to write out the equations before estimating (NOT REQUIRED)*\n",
    "    - *At least do it on paper first*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-poster",
   "metadata": {},
   "source": [
    "Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virgin-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-creek",
   "metadata": {},
   "source": [
    "***********\n",
    "## [10 Points] Sigmoid Log-Odds\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "When I showed how we can rearrange the sigmoid function to probabilities in the Regression-based Classification lecture, I was lazy and skipped several steps.\n",
    "Help me out by showing me how to show my work.\n",
    "\n",
    "Show how we can start with $p(X) = \\frac{e^{\\alpha + X \\beta}}{1+e^{\\alpha + X \\beta}}$ and rearrange to get $log \\left( \\frac{p(X)}{1-p(X)} \\right) = \\alpha + X \\beta$ in **at least five lines** (there should be at least five `=` signs including the ones I have povided)\n",
    "\n",
    "**[10 points]** - $\\geq$ 5 lines\n",
    "\n",
    "**[5 points]** -  4 lines\n",
    "\n",
    "**[0 points]** - $\\leq$ 3 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-rachel",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  p(X) & = \\frac{e^{\\alpha + X \\beta}}{1+e^{\\alpha + X \\beta}}\\\\\n",
    "  & \\vdots\\\\\n",
    "  log \\left( \\frac{p(X)}{1-p(X)} \\right) & = \\alpha + X \\beta\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-lesbian",
   "metadata": {},
   "source": [
    "********\n",
    "# Application\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "This homework's application is based around predicting an individuals degree (`degree`). \n",
    "We will compare the performance of three different models to the null model:\n",
    "\n",
    "1. Multinomial logisitic regression\n",
    "2. K nearest neighbors\n",
    "3. Gaussian Naive Bayes\n",
    "\n",
    "We will be using **standardized features in all models**.\n",
    "\n",
    "********\n",
    "## [16 Points] Preliminaries\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "**[8 points]** Import:\n",
    "\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `tqdm`\n",
    "- `KFold()`\n",
    "- `train_test_split()`\n",
    "- `StandardScalar()` (optional)\n",
    "- `statsmodels.api`\n",
    "- `KNeighborsClassifier()`\n",
    "- `GaussianNB()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-alaska",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sporting-fishing",
   "metadata": {},
   "source": [
    "**[2 points]** Load in the data as `df`. Deal with any variables that need to put into the index (`.set_index()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-liberal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "strong-chancellor",
   "metadata": {},
   "source": [
    "- **[2 points]** Define `x` and `y`\n",
    "    - Remember to make `y` a `category` type!\n",
    "- **[2 points]** Perform a train-test split on `x` and `y` using a `train_size` of 5% and a `random_state` of 490\n",
    "- **[2 points]** Overwrite `x_train` and `x_test` with their standardized transformations using either a lambda function or `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "surgical-newspaper",
   "metadata": {},
   "source": [
    "**************\n",
    "## [4 Points] Null Model \n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "\n",
    "**[4 points]** Determine which class we will be predicting in the null model and evaluate (save) then print the null model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-olive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "retired-benefit",
   "metadata": {},
   "source": [
    "*************\n",
    "## [17 Points] Logistic Regression \n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "**[2 points]** Use `statsmodels.api` to fit a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-eight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fatty-invalid",
   "metadata": {},
   "source": [
    "**[4 points]** Interpret the coefficient on `occ_ba` for `degree = some college`. \n",
    "**_Remember we standardized all variables!_**\n",
    "\n",
    "*Hint: what is the __unit__ for all variables? What does an increase by one correspond to? Think about the standardization formula's denominator.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-district",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "careful-verse",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-michigan",
   "metadata": {},
   "source": [
    "**[4 points]**  Interpret the marginal effects for the same coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-hotel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "through-stability",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-galaxy",
   "metadata": {},
   "source": [
    "- Print the head of the predicted values of the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-advisory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collectible-indonesian",
   "metadata": {},
   "source": [
    "- **[3 points]** Create `yhat` by\n",
    "    1. predicting using the testing data\n",
    "    2. chain `.idxmax()` on step 1 with the argument `axis = 1`\n",
    "    3. put step 1 and step 2 inside of the `[]` from  `y_test.cat.categories[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-jackson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "congressional-investment",
   "metadata": {},
   "source": [
    "**[2 points]** Save and print the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-iceland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "funded-immigration",
   "metadata": {},
   "source": [
    "***\n",
    "## [14 Points] KNN\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "In this section, we will fit a `KneighborsClassifier()` using 5-fold cross validation.\n",
    "\n",
    "In one code cell\n",
    "\n",
    "- replicate the code cell from the workshop 12 ML Classification solutions to identify the optimal value of $k$.\n",
    "- adjust the workshop code cell to fit a grid with values that are multiples of from 5 to 50 (i.e. 5, 10, 15, ..., 50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-effect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-nigeria",
   "metadata": {},
   "source": [
    "- **[5 points]** Print the optimal or corner-solution value of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-generation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cleared-reaction",
   "metadata": {},
   "source": [
    "In order for KNN to predict, it needs to evaluate the closest neighbors first. \n",
    "This is computationally expensive.\n",
    "\n",
    "Our testing data is approximately 750,000 observations. \n",
    "We don't need to test every single observation in the test set.\n",
    "The difference from 75,000 to 750,000 won't influence our accuracy measures significantly.\n",
    "\n",
    "A **useful technique** is to reduce an excessive size to a manageable size to balance the computation time.\n",
    "\n",
    "**[2 points]** Create `x_test_knn` and `y_test_knn` using the method `.sample()` on the testing data specifying the arguments `frac = 0.1` and a random state of 490 (Doing so reduces the computation down from 5 minutes to about 30 seconds on my computer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "auburn-phoenix",
   "metadata": {},
   "source": [
    "Using the identified optial value of $k$\n",
    "\n",
    "- Add an optional `%%time` to the top of your code cell\n",
    "- **[2 points]** fit your KNN classifier as `knn` using the optimal value of $k$\n",
    "- **[2 points]** save and then print the accuracy using the `.score()` method on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-poison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-expansion",
   "metadata": {},
   "source": [
    "*****************\n",
    "## [4 Points] Gaussian Naive Bayes\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "- **[2 points]** fit a Gaussian naive Bayes model on the training data as `gnb`\n",
    "- **[2 points]** save and print the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-stadium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handled-terrace",
   "metadata": {},
   "source": [
    "********\n",
    "## [5 Points] Comparison\n",
    "[TOP](#Homework-3---Classy-Validity)\n",
    "\n",
    "**[3 points]** However you see best, print out the percent improvement of the three models relative to the null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-venezuela",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-bridges",
   "metadata": {},
   "source": [
    "**[2 points]** Given these improvements, which model would you choose?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
